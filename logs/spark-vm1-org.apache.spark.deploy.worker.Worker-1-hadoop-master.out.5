Spark Command: /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -cp /usr/local/spark-2.3.2-bin-hadoop2.7/conf/:/usr/local/spark-2.3.2-bin-hadoop2.7/assembly/target/scala-2.11/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://10.193.232.252:7077
========================================
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
18/10/30 21:06:58 INFO Worker: Started daemon with process name: 13108@hadoop-master
18/10/30 21:06:58 INFO SignalUtils: Registered signal handler for TERM
18/10/30 21:06:58 INFO SignalUtils: Registered signal handler for HUP
18/10/30 21:06:58 INFO SignalUtils: Registered signal handler for INT
18/10/30 21:06:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/10/30 21:06:58 INFO SecurityManager: Changing view acls to: vm1
18/10/30 21:06:58 INFO SecurityManager: Changing modify acls to: vm1
18/10/30 21:06:58 INFO SecurityManager: Changing view acls groups to: 
18/10/30 21:06:58 INFO SecurityManager: Changing modify acls groups to: 
18/10/30 21:06:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(vm1); groups with view permissions: Set(); users  with modify permissions: Set(vm1); groups with modify permissions: Set()
18/10/30 21:06:59 INFO Utils: Successfully started service 'sparkWorker' on port 40379.
18/10/30 21:06:59 INFO Worker: Starting Spark worker 10.193.232.252:40379 with 8 cores, 4.8 GB RAM
18/10/30 21:06:59 INFO Worker: Running Spark version 2.3.2
18/10/30 21:06:59 INFO Worker: Spark home: /usr/local/spark-2.3.2-bin-hadoop2.7
18/10/30 21:06:59 INFO log: Logging initialized @1808ms
18/10/30 21:06:59 INFO Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T12:11:56-05:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
18/10/30 21:06:59 INFO Server: Started @1881ms
18/10/30 21:06:59 INFO AbstractConnector: Started ServerConnector@30ed54b5{HTTP/1.1,[http/1.1]}{0.0.0.0:8081}
18/10/30 21:06:59 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
18/10/30 21:06:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@454571a5{/logPage,null,AVAILABLE,@Spark}
18/10/30 21:06:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2f13fa45{/logPage/json,null,AVAILABLE,@Spark}
18/10/30 21:06:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@59315f69{/,null,AVAILABLE,@Spark}
18/10/30 21:06:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@9869c87{/json,null,AVAILABLE,@Spark}
18/10/30 21:06:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5a9f50c9{/static,null,AVAILABLE,@Spark}
18/10/30 21:06:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6267907d{/log,null,AVAILABLE,@Spark}
18/10/30 21:06:59 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://hadoop-master:8081
18/10/30 21:06:59 INFO Worker: Connecting to master 10.193.232.252:7077...
18/10/30 21:06:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@352ed37e{/metrics/json,null,AVAILABLE,@Spark}
18/10/30 21:06:59 INFO TransportClientFactory: Successfully created connection to /10.193.232.252:7077 after 37 ms (0 ms spent in bootstraps)
18/10/30 21:06:59 INFO Worker: Successfully registered with master spark://10.193.232.252:7077
18/10/30 21:07:04 INFO Worker: Asked to launch executor app-20181030210704-0000/0 for engaging_reviews
18/10/30 21:07:04 INFO SecurityManager: Changing view acls to: vm1
18/10/30 21:07:04 INFO SecurityManager: Changing modify acls to: vm1
18/10/30 21:07:04 INFO SecurityManager: Changing view acls groups to: 
18/10/30 21:07:04 INFO SecurityManager: Changing modify acls groups to: 
18/10/30 21:07:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(vm1); groups with view permissions: Set(); users  with modify permissions: Set(vm1); groups with modify permissions: Set()
18/10/30 21:07:04 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java" "-cp" "/usr/local/spark-2.3.2-bin-hadoop2.7/conf/:/usr/local/spark-2.3.2-bin-hadoop2.7/assembly/target/scala-2.11/jars/*" "-Xmx1024M" "-Dspark.driver.port=41449" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@hadoop-master:41449" "--executor-id" "0" "--hostname" "10.193.232.252" "--cores" "8" "--app-id" "app-20181030210704-0000" "--worker-url" "spark://Worker@10.193.232.252:40379"
18/10/30 21:07:38 INFO Worker: Asked to kill executor app-20181030210704-0000/0
18/10/30 21:07:38 INFO ExecutorRunner: Runner thread for executor app-20181030210704-0000/0 interrupted
18/10/30 21:07:38 INFO ExecutorRunner: Killing process!
18/10/30 21:07:38 INFO Worker: Executor app-20181030210704-0000/0 finished with state KILLED exitStatus 143
18/10/30 21:07:38 INFO ExternalShuffleBlockResolver: Application app-20181030210704-0000 removed, cleanupLocalDirs = true
18/10/30 21:07:38 INFO Worker: Cleaning up local directories for application app-20181030210704-0000
18/10/30 21:08:37 ERROR Worker: RECEIVED SIGNAL TERM
18/10/30 21:08:37 INFO ShutdownHookManager: Shutdown hook called
18/10/30 21:08:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-b2bee554-76a7-477a-8b6d-3440e758b34e
