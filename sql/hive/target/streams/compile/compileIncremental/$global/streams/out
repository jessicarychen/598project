[0m[[0mdebug[0m] [0m[naha] [0m
[0m[[0mdebug[0m] [0m[naha] Initial source changes: [0m
[0m[[0mdebug[0m] [0m[naha] 	removed:Set()[0m
[0m[[0mdebug[0m] [0m[naha] 	added: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveInspectors.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveDirCommand.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/IsolatedClientLoader.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/ScriptTransformationExec.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFilters.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileOperator.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveExternalCatalog.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveTable.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/java/org/apache/hadoop/hive/ql/io/orc/SparkOrcNewRecordReader.java, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/package.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveFileFormat.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionCatalog.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClient.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveTableScanExec.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveMetastoreCatalog.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package-info.java, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveShim.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveOptions.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/CreateHiveTableAsSelectCommand.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/TableReader.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveUtils.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveShim.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileFormat.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/hiveUDFs.scala)[0m
[0m[[0mdebug[0m] [0m[naha] 	modified: Set()[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated products: Set()[0m
[0m[[0mdebug[0m] [0m[naha] External API changes: API Changes: Set()[0m
[0m[[0mdebug[0m] [0m[naha] Modified binary dependencies: Set()[0m
[0m[[0mdebug[0m] [0m[naha] Initial directly invalidated sources: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveInspectors.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveDirCommand.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/IsolatedClientLoader.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/ScriptTransformationExec.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFilters.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileOperator.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveExternalCatalog.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveTable.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/java/org/apache/hadoop/hive/ql/io/orc/SparkOrcNewRecordReader.java, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/package.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveFileFormat.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionCatalog.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClient.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveTableScanExec.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveMetastoreCatalog.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package-info.java, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveShim.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveOptions.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/CreateHiveTableAsSelectCommand.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/TableReader.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveUtils.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveShim.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileFormat.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/hiveUDFs.scala)[0m
[0m[[0mdebug[0m] [0m[naha] [0m
[0m[[0mdebug[0m] [0m[naha] Sources indirectly invalidated by:[0m
[0m[[0mdebug[0m] [0m[naha] 	product: Set()[0m
[0m[[0mdebug[0m] [0m[naha] 	binary dep: Set()[0m
[0m[[0mdebug[0m] [0m[naha] 	external source: Set()[0m
[0m[[0mdebug[0m] [0mAll initially invalidated sources: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveInspectors.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveDirCommand.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/IsolatedClientLoader.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/ScriptTransformationExec.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFilters.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileOperator.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveExternalCatalog.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveTable.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/java/org/apache/hadoop/hive/ql/io/orc/SparkOrcNewRecordReader.java, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/package.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveFileFormat.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionCatalog.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClient.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveTableScanExec.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveMetastoreCatalog.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package-info.java, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveShim.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveOptions.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/CreateHiveTableAsSelectCommand.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/TableReader.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveUtils.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveShim.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileFormat.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/hiveUDFs.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveInspectors.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveDirCommand.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/IsolatedClientLoader.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/ScriptTransformationExec.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFilters.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileOperator.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveExternalCatalog.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveTable.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/java/org/apache/hadoop/hive/ql/io/orc/SparkOrcNewRecordReader.java, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/package.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveFileFormat.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionCatalog.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClient.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveTableScanExec.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveMetastoreCatalog.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package-info.java, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveShim.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveOptions.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/CreateHiveTableAsSelectCommand.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/TableReader.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveUtils.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveShim.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileFormat.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/hiveUDFs.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Recompiling all 31 sources: invalidated sources (31) exceeded 50.0% of all sources[0m
[0m[[0minfo[0m] [0mCompiling 29 Scala sources and 2 Java sources to /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/target/scala-2.11/classes...[0m
[0m[[0mdebug[0m] [0mGetting org.scala-sbt:compiler-interface:0.13.16:component from component compiler for Scala 2.11.8[0m
[0m[[0mdebug[0m] [0mGetting org.scala-sbt:compiler-interface:0.13.16:component from component compiler for Scala 2.11.8[0m
[0m[[0mdebug[0m] [0mRunning cached compiler 79f976a6, interfacing (CompilerInterface) with Scala compiler version 2.11.8[0m
[0m[[0mdebug[0m] [0mCalling Scala compiler with arguments  (CompilerInterface):[0m
[0m[[0mdebug[0m] [0m	-unchecked[0m
[0m[[0mdebug[0m] [0m	-feature[0m
[0m[[0mdebug[0m] [0m	-explaintypes[0m
[0m[[0mdebug[0m] [0m	-Yno-adapted-args[0m
[0m[[0mdebug[0m] [0m	-P:genjavadoc:out=/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/target/java[0m
[0m[[0mdebug[0m] [0m	-P:genjavadoc:strictVisibility=true[0m
[0m[[0mdebug[0m] [0m	-Xplugin:/home/vm1/.ivy2/cache/com.typesafe.genjavadoc/genjavadoc-plugin_2.11.8/jars/genjavadoc-plugin_2.11.8-0.10.jar[0m
[0m[[0mdebug[0m] [0m	-target:jvm-1.8[0m
[0m[[0mdebug[0m] [0m	-sourcepath[0m
[0m[[0mdebug[0m] [0m	/usr/local/spark-2.3.2-bin-hadoop2.7[0m
[0m[[0mdebug[0m] [0m	-bootclasspath[0m
[0m[[0mdebug[0m] [0m	/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes:/home/vm1/.ivy2/cache/org.scala-lang/scala-library/jars/scala-library-2.11.8.jar[0m
[0m[[0mdebug[0m] [0m	-classpath[0m
[0m[[0mdebug[0m] [0m	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/target/scala-2.11/classes:/usr/local/spark-2.3.2-bin-hadoop2.7/core/target/scala-2.11/spark-core_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/launcher/target/scala-2.11/spark-launcher_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/common/tags/target/scala-2.11/spark-tags_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/common/kvstore/target/scala-2.11/spark-kvstore_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/common/network-common/target/scala-2.11/spark-network-common_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/common/network-shuffle/target/scala-2.11/spark-network-shuffle_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/common/unsafe/target/scala-2.11/spark-unsafe_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/sql/core/target/scala-2.11/spark-sql_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/common/sketch/target/scala-2.11/spark-sketch_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/sql/catalyst/target/scala-2.11/spark-catalyst_2.11-2.3.2.jar:/home/vm1/.ivy2/cache/org.spark-project.spark/unused/jars/unused-1.0.0.jar:/home/vm1/.ivy2/cache/com.google.guava/guava/bundles/guava-14.0.1.jar:/home/vm1/.ivy2/cache/org.jpmml/pmml-model/jars/pmml-model-1.2.15.jar:/home/vm1/.ivy2/cache/org.jpmml/pmml-schema/jars/pmml-schema-1.2.15.jar:/home/vm1/.ivy2/cache/org.fusesource.leveldbjni/leveldbjni-all/bundles/leveldbjni-all-1.8.jar:/home/vm1/.ivy2/cache/com.fasterxml.jackson.core/jackson-databind/bundles/jackson-databind-2.6.7.1.jar:/home/vm1/.ivy2/cache/com.fasterxml.jackson.core/jackson-annotations/bundles/jackson-annotations-2.6.7.jar:/home/vm1/.ivy2/cache/io.netty/netty-all/jars/netty-all-4.1.17.Final.jar:/home/vm1/.ivy2/cache/org.apache.commons/commons-lang3/jars/commons-lang3-3.5.jar:/home/vm1/.ivy2/cache/io.dropwizard.metrics/metrics-core/bundles/metrics-core-3.1.5.jar:/home/vm1/.ivy2/cache/org.apache.commons/commons-crypto/jars/commons-crypto-1.0.0.jar:/home/vm1/.ivy2/cache/com.twitter/chill_2.11/jars/chill_2.11-0.8.4.jar:/home/vm1/.ivy2/cache/com.twitter/chill-java/jars/chill-java-0.8.4.jar:/home/vm1/.ivy2/cache/com.esotericsoftware/kryo-shaded/bundles/kryo-shaded-3.0.3.jar:/home/vm1/.ivy2/cache/com.esotericsoftware/minlog/bundles/minlog-1.3.0.jar:/home/vm1/.ivy2/cache/org.objenesis/objenesis/jars/objenesis-2.1.jar:/home/vm1/.ivy2/cache/org.apache.avro/avro/jars/avro-1.7.7.jar:/home/vm1/.ivy2/cache/org.codehaus.jackson/jackson-core-asl/jars/jackson-core-asl-1.9.13.jar:/home/vm1/.ivy2/cache/org.codehaus.jackson/jackson-mapper-asl/jars/jackson-mapper-asl-1.9.13.jar:/home/vm1/.ivy2/cache/org.xerial.snappy/snappy-java/bundles/snappy-java-1.1.2.6.jar:/home/vm1/.ivy2/cache/org.apache.commons/commons-compress/jars/commons-compress-1.4.1.jar:/home/vm1/.ivy2/cache/org.tukaani/xz/jars/xz-1.0.jar:/home/vm1/.ivy2/cache/org.apache.avro/avro-mapred/jars/avro-mapred-1.7.7-hadoop2.jar:/home/vm1/.ivy2/cache/org.apache.avro/avro-ipc/jars/avro-ipc-1.7.7-tests.jar:/home/vm1/.ivy2/cache/org.apache.avro/avro-ipc/jars/avro-ipc-1.7.7.jar:/home/vm1/.ivy2/cache/org.apache.xbean/xbean-asm5-shaded/bundles/xbean-asm5-shaded-4.4.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-client/jars/hadoop-client-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-common/jars/hadoop-common-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-annotations/jars/hadoop-annotations-2.6.5.jar:/home/vm1/.ivy2/cache/commons-cli/commons-cli/jars/commons-cli-1.2.jar:/home/vm1/.ivy2/cache/org.apache.commons/commons-math3/jars/commons-math3-3.4.1.jar:/home/vm1/.ivy2/cache/xmlenc/xmlenc/jars/xmlenc-0.52.jar:/home/vm1/.ivy2/cache/commons-httpclient/commons-httpclient/jars/commons-httpclient-3.1.jar:/home/vm1/.ivy2/cache/commons-io/commons-io/jars/commons-io-2.4.jar:/home/vm1/.ivy2/cache/commons-net/commons-net/jars/commons-net-3.1.jar:/home/vm1/.ivy2/cache/commons-collections/commons-collections/jars/commons-collections-3.2.2.jar:/home/vm1/.ivy2/cache/log4j/log4j/bundles/log4j-1.2.17.jar:/home/vm1/.ivy2/cache/commons-lang/commons-lang/jars/commons-lang-2.6.jar:/home/vm1/.ivy2/cache/commons-configuration/commons-configuration/jars/commons-configuration-1.6.jar:/home/vm1/.ivy2/cache/commons-digester/commons-digester/jars/commons-digester-1.8.jar:/home/vm1/.ivy2/cache/commons-beanutils/commons-beanutils/jars/commons-beanutils-1.7.0.jar:/home/vm1/.ivy2/cache/commons-beanutils/commons-beanutils-core/jars/commons-beanutils-core-1.8.0.jar:/home/vm1/.ivy2/cache/com.google.protobuf/protobuf-java/bundles/protobuf-java-2.5.0.jar:/home/vm1/.ivy2/cache/com.google.code.gson/gson/jars/gson-2.2.4.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-auth/jars/hadoop-auth-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.httpcomponents/httpclient/jars/httpclient-4.5.4.jar:/home/vm1/.ivy2/cache/org.apache.httpcomponents/httpcore/jars/httpcore-4.4.7.jar:/home/vm1/.ivy2/cache/commons-logging/commons-logging/jars/commons-logging-1.2.jar:/home/vm1/.ivy2/cache/org.apache.directory.server/apacheds-kerberos-codec/bundles/apacheds-kerberos-codec-2.0.0-M15.jar:/home/vm1/.ivy2/cache/org.apache.directory.server/apacheds-i18n/bundles/apacheds-i18n-2.0.0-M15.jar:/home/vm1/.ivy2/cache/org.apache.directory.api/api-asn1-api/bundles/api-asn1-api-1.0.0-M20.jar:/home/vm1/.ivy2/cache/org.apache.directory.api/api-util/bundles/api-util-1.0.0-M20.jar:/home/vm1/.ivy2/cache/org.apache.curator/curator-framework/bundles/curator-framework-2.6.0.jar:/home/vm1/.ivy2/cache/org.apache.curator/curator-client/bundles/curator-client-2.6.0.jar:/home/vm1/.ivy2/cache/org.apache.zookeeper/zookeeper/jars/zookeeper-3.4.6.jar:/home/vm1/.ivy2/cache/jline/jline/jars/jline-0.9.94.jar:/home/vm1/.ivy2/cache/io.netty/netty/bundles/netty-3.9.9.Final.jar:/home/vm1/.ivy2/cache/org.apache.curator/curator-recipes/bundles/curator-recipes-2.6.0.jar:/home/vm1/.ivy2/cache/org.htrace/htrace-core/jars/htrace-core-3.0.4.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-hdfs/jars/hadoop-hdfs-2.6.5.jar:/home/vm1/.ivy2/cache/org.mortbay.jetty/jetty-util/jars/jetty-util-6.1.26.jar:/home/vm1/.ivy2/cache/xerces/xercesImpl/jars/xercesImpl-2.9.1.jar:/home/vm1/.ivy2/cache/xml-apis/xml-apis/jars/xml-apis-1.3.04.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-mapreduce-client-app/jars/hadoop-mapreduce-client-app-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-mapreduce-client-common/jars/hadoop-mapreduce-client-common-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-yarn-common/jars/hadoop-yarn-common-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-yarn-api/jars/hadoop-yarn-api-2.6.5.jar:/home/vm1/.ivy2/cache/javax.xml.bind/jaxb-api/jars/jaxb-api-2.2.2.jar:/home/vm1/.ivy2/cache/javax.xml.stream/stax-api/jars/stax-api-1.0-2.jar:/home/vm1/.ivy2/cache/org.codehaus.jackson/jackson-jaxrs/jars/jackson-jaxrs-1.9.13.jar:/home/vm1/.ivy2/cache/org.codehaus.jackson/jackson-xc/jars/jackson-xc-1.9.13.jar:/home/vm1/.ivy2/cache/com.google.inject/guice/jars/guice-3.0.jar:/home/vm1/.ivy2/cache/javax.inject/javax.inject/jars/javax.inject-1.jar:/home/vm1/.ivy2/cache/aopalliance/aopalliance/jars/aopalliance-1.0.jar:/home/vm1/.ivy2/cache/org.sonatype.sisu.inject/cglib/jars/cglib-2.2.1-v20090111.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-yarn-client/jars/hadoop-yarn-client-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-mapreduce-client-core/jars/hadoop-mapreduce-client-core-2.6.5.jar:/home/vm1/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.16.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-yarn-server-common/jars/hadoop-yarn-server-common-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-mapreduce-client-shuffle/jars/hadoop-mapreduce-client-shuffle-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-mapreduce-client-jobclient/jars/hadoop-mapreduce-client-jobclient-2.6.5.jar:/home/vm1/.ivy2/cache/org.codehaus.jettison/jettison/bundles/jettison-1.1.jar:/home/vm1/.ivy2/cache/net.java.dev.jets3t/jets3t/jars/jets3t-0.9.4.jar:/home/vm1/.ivy2/cache/commons-codec/commons-codec/jars/commons-codec-1.11.jar:/home/vm1/.ivy2/cache/javax.activation/activation/jars/activation-1.1.1.jar:/home/vm1/.ivy2/cache/org.bouncycastle/bcprov-jdk15on/jars/bcprov-jdk15on-1.52.jar:/home/vm1/.ivy2/cache/com.jamesmurty.utils/java-xmlbuilder/jars/java-xmlbuilder-1.1.jar:/home/vm1/.ivy2/cache/net.iharder/base64/jars/base64-2.3.8.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-plus/jars/jetty-plus-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-webapp/jars/jetty-webapp-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-xml/jars/jetty-xml-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-util/jars/jetty-util-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-servlet/jars/jetty-servlet-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-security/jars/jetty-security-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-server/jars/jetty-server-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/javax.servlet/javax.servlet-api/jars/javax.servlet-api-3.1.0.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-http/jars/jetty-http-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-io/jars/jetty-io-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-jndi/jars/jetty-jndi-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-continuation/jars/jetty-continuation-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-proxy/jars/jetty-proxy-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-client/jars/jetty-client-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-servlets/jars/jetty-servlets-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.slf4j/jul-to-slf4j/jars/jul-to-slf4j-1.7.16.jar:/home/vm1/.ivy2/cache/org.slf4j/jcl-over-slf4j/jars/jcl-over-slf4j-1.7.16.jar:/home/vm1/.ivy2/cache/com.ning/compress-lzf/bundles/compress-lzf-1.0.3.jar:/home/vm1/.ivy2/cache/org.lz4/lz4-java/jars/lz4-java-1.4.0.jar:/home/vm1/.ivy2/cache/com.github.luben/zstd-jni/bundles/zstd-jni-1.3.2-2.jar:/home/vm1/.ivy2/cache/org.roaringbitmap/RoaringBitmap/bundles/RoaringBitmap-0.5.11.jar:/home/vm1/.ivy2/cache/org.json4s/json4s-jackson_2.11/jars/json4s-jackson_2.11-3.2.11.jar:/home/vm1/.ivy2/cache/org.json4s/json4s-core_2.11/jars/json4s-core_2.11-3.2.11.jar:/home/vm1/.ivy2/cache/org.json4s/json4s-ast_2.11/jars/json4s-ast_2.11-3.2.11.jar:/home/vm1/.ivy2/cache/org.scala-lang/scalap/jars/scalap-2.11.8.jar:/home/vm1/.ivy2/cache/org.scala-lang/scala-compiler/jars/scala-compiler-2.11.8.jar:/home/vm1/.ivy2/cache/org.scala-lang/scala-reflect/jars/scala-reflect-2.11.8.jar:/home/vm1/.ivy2/cache/org.scala-lang.modules/scala-xml_2.11/bundles/scala-xml_2.11-1.0.4.jar:/home/vm1/.ivy2/cache/org.scala-lang.modules/scala-parser-combinators_2.11/bundles/scala-parser-combinators_2.11-1.0.4.jar:/home/vm1/.ivy2/cache/org.glassfish.jersey.core/jersey-client/jars/jersey-client-2.22.2.jar:/home/vm1/.ivy2/cache/javax.ws.rs/javax.ws.rs-api/jars/javax.ws.rs-api-2.0.1.jar:/home/vm1/.ivy2/cache/org.glassfish.jersey.core/jersey-common/jars/jersey-common-2.22.2.jar:/home/vm1/.ivy2/cache/javax.annotation/javax.annotation-api/jars/javax.annotation-api-1.2.jar:/home/vm1/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar:/home/vm1/.ivy2/cache/org.glassfish.hk2/hk2-api/jars/hk2-api-2.4.0-b34.jar:/home/vm1/.ivy2/cache/org.glassfish.hk2/hk2-utils/jars/hk2-utils-2.4.0-b34.jar:/home/vm1/.ivy2/cache/org.glassfish.hk2.external/aopalliance-repackaged/jars/aopalliance-repackaged-2.4.0-b34.jar:/home/vm1/.ivy2/cache/org.glassfish.hk2.external/javax.inject/jars/javax.inject-2.4.0-b34.jar:/home/vm1/.ivy2/cache/org.glassfish.hk2/hk2-locator/jars/hk2-locator-2.4.0-b34.jar:/home/vm1/.ivy2/cache/org.javassist/javassist/bundles/javassist-3.18.1-GA.jar:/home/vm1/.ivy2/cache/org.glassfish.hk2/osgi-resource-locator/jars/osgi-resource-locator-1.0.1.jar:/home/vm1/.ivy2/cache/org.glassfish.jersey.core/jersey-server/jars/jersey-server-2.22.2.jar:/home/vm1/.ivy2/cache/org.glassfish.jersey.media/jersey-media-jaxb/jars/jersey-media-jaxb-2.22.2.jar:/home/vm1/.ivy2/cache/javax.validation/validation-api/jars/validation-api-1.1.0.Final.jar:/home/vm1/.ivy2/cache/org.glassfish.jersey.containers/jersey-container-servlet/jars/jersey-container-servlet-2.22.2.jar:/home/vm1/.ivy2/cache/org.glassfish.jersey.containers/jersey-container-servlet-core/jars/jersey-container-servlet-core-2.22.2.jar:/home/vm1/.ivy2/cache/com.clearspring.analytics/stream/jars/stream-2.7.0.jar:/home/vm1/.ivy2/cache/io.dropwizard.metrics/metrics-jvm/bundles/metrics-jvm-3.1.5.jar:/home/vm1/.ivy2/cache/io.dropwizard.metrics/metrics-json/bundles/metrics-json-3.1.5.jar:/home/vm1/.ivy2/cache/io.dropwizard.metrics/metrics-graphite/bundles/metrics-graphite-3.1.5.jar:/home/vm1/.ivy2/cache/com.fasterxml.jackson.module/jackson-module-scala_2.11/bundles/jackson-module-scala_2.11-2.6.7.1.jar:/home/vm1/.ivy2/cache/com.fasterxml.jackson.module/jackson-module-paranamer/bundles/jackson-module-paranamer-2.7.9.jar:/home/vm1/.ivy2/cache/com.thoughtworks.paranamer/paranamer/bundles/paranamer-2.8.jar:/home/vm1/.ivy2/cache/org.apache.ivy/ivy/jars/ivy-2.4.0.jar:/home/vm1/.ivy2/cache/oro/oro/jars/oro-2.0.8.jar:/home/vm1/.ivy2/cache/net.razorvine/pyrolite/jars/pyrolite-4.13.jar:/home/vm1/.ivy2/cache/net.sf.py4j/py4j/jars/py4j-0.10.7.jar:/home/vm1/.ivy2/cache/org.codehaus.janino/janino/jars/janino-3.0.8.jar:/home/vm1/.ivy2/cache/org.codehaus.janino/commons-compiler/jars/commons-compiler-3.0.8.jar:/home/vm1/.ivy2/cache/org.antlr/antlr4-runtime/jars/antlr4-runtime-4.7.jar:/home/vm1/.ivy2/cache/com.univocity/univocity-parsers/jars/univocity-parsers-2.5.9.jar:/home/vm1/.ivy2/cache/org.apache.orc/orc-core/jars/orc-core-1.4.4-nohive.jar:/home/vm1/.ivy2/cache/io.airlift/aircompressor/jars/aircompressor-0.8.jar:/home/vm1/.ivy2/cache/org.apache.orc/orc-mapreduce/jars/orc-mapreduce-1.4.4-nohive.jar:/home/vm1/.ivy2/cache/org.apache.parquet/parquet-column/jars/parquet-column-1.8.3.jar:/home/vm1/.ivy2/cache/org.apache.parquet/parquet-common/jars/parquet-common-1.8.3.jar:/home/vm1/.ivy2/cache/org.apache.parquet/parquet-encoding/jars/parquet-encoding-1.8.3.jar:/home/vm1/.ivy2/cache/org.apache.parquet/parquet-hadoop/jars/parquet-hadoop-1.8.3.jar:/home/vm1/.ivy2/cache/org.apache.parquet/parquet-format/jars/parquet-format-2.3.1.jar:/home/vm1/.ivy2/cache/org.apache.parquet/parquet-jackson/jars/parquet-jackson-1.8.3.jar:/home/vm1/.ivy2/cache/org.apache.arrow/arrow-vector/jars/arrow-vector-0.8.0.jar:/home/vm1/.ivy2/cache/org.apache.arrow/arrow-format/jars/arrow-format-0.8.0.jar:/home/vm1/.ivy2/cache/com.vlkan/flatbuffers/jars/flatbuffers-1.2.0-3f79e055.jar:/home/vm1/.ivy2/cache/org.apache.arrow/arrow-memory/jars/arrow-memory-0.8.0.jar:/home/vm1/.ivy2/cache/com.google.code.findbugs/jsr305/jars/jsr305-3.0.2.jar:/home/vm1/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.25.jar:/home/vm1/.ivy2/cache/joda-time/joda-time/jars/joda-time-2.9.9.jar:/home/vm1/.ivy2/cache/com.fasterxml.jackson.core/jackson-core/bundles/jackson-core-2.7.9.jar:/home/vm1/.ivy2/cache/com.carrotsearch/hppc/bundles/hppc-0.7.2.jar:/home/vm1/.ivy2/cache/com.twitter/parquet-hadoop-bundle/jars/parquet-hadoop-bundle-1.6.0.jar:/home/vm1/.ivy2/cache/org.spark-project.hive/hive-exec/jars/hive-exec-1.2.1.spark2.jar:/home/vm1/.ivy2/cache/javolution/javolution/bundles/javolution-5.5.1.jar:/home/vm1/.ivy2/cache/log4j/apache-log4j-extras/bundles/apache-log4j-extras-1.2.17.jar:/home/vm1/.ivy2/cache/org.antlr/antlr-runtime/jars/antlr-runtime-3.4.jar:/home/vm1/.ivy2/cache/org.antlr/stringtemplate/jars/stringtemplate-3.2.1.jar:/home/vm1/.ivy2/cache/antlr/antlr/jars/antlr-2.7.7.jar:/home/vm1/.ivy2/cache/org.antlr/ST4/jars/ST4-4.0.4.jar:/home/vm1/.ivy2/cache/org.jodd/jodd-core/jars/jodd-core-3.5.2.jar:/home/vm1/.ivy2/cache/org.datanucleus/datanucleus-core/jars/datanucleus-core-3.2.10.jar:/home/vm1/.ivy2/cache/org.apache.calcite/calcite-avatica/jars/calcite-avatica-1.2.0-incubating.jar:/home/vm1/.ivy2/cache/com.googlecode.javaewah/JavaEWAH/jars/JavaEWAH-0.3.2.jar:/home/vm1/.ivy2/cache/org.iq80.snappy/snappy/jars/snappy-0.2.jar:/home/vm1/.ivy2/cache/stax/stax-api/jars/stax-api-1.0.1.jar:/home/vm1/.ivy2/cache/net.sf.opencsv/opencsv/jars/opencsv-2.3.jar:/home/vm1/.ivy2/cache/org.spark-project.hive/hive-metastore/jars/hive-metastore-1.2.1.spark2.jar:/home/vm1/.ivy2/cache/com.jolbox/bonecp/bundles/bonecp-0.8.0.RELEASE.jar:/home/vm1/.ivy2/cache/org.apache.derby/derby/jars/derby-10.12.1.1.jar:/home/vm1/.ivy2/cache/org.datanucleus/datanucleus-api-jdo/jars/datanucleus-api-jdo-3.2.6.jar:/home/vm1/.ivy2/cache/org.datanucleus/datanucleus-rdbms/jars/datanucleus-rdbms-3.2.9.jar:/home/vm1/.ivy2/cache/commons-pool/commons-pool/jars/commons-pool-1.5.4.jar:/home/vm1/.ivy2/cache/commons-dbcp/commons-dbcp/jars/commons-dbcp-1.4.jar:/home/vm1/.ivy2/cache/javax.jdo/jdo-api/jars/jdo-api-3.0.1.jar:/home/vm1/.ivy2/cache/javax.transaction/jta/jars/jta-1.1.jar:/home/vm1/.ivy2/cache/org.apache.calcite/calcite-core/jars/calcite-core-1.2.0-incubating.jar:/home/vm1/.ivy2/cache/org.apache.calcite/calcite-linq4j/jars/calcite-linq4j-1.2.0-incubating.jar:/home/vm1/.ivy2/cache/net.hydromatic/eigenbase-properties/bundles/eigenbase-properties-1.1.5.jar:/home/vm1/.ivy2/cache/org.apache.thrift/libthrift/jars/libthrift-0.9.3.jar:/home/vm1/.ivy2/cache/org.apache.thrift/libfb303/jars/libfb303-0.9.3.jar[0m
[0m[[33mwarn[0m] [0mthere were 24 deprecation warnings; re-run with -deprecation for details[0m
[0m[[33mwarn[0m] [0mone warning found[0m
[0m[[0mdebug[0m] [0mScala compilation took 8.894889256 s[0m
[0m[[0mdebug[0m] [0mJava compilation took 1.233615604 s[0m
[0m[[0mdebug[0m] [0mJava analysis took 0.044883811 s[0m
[0m[[0mdebug[0m] [0mJava compile + analysis took 1.288557292 s[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/java/org/apache/hadoop/hive/ql/io/orc/SparkOrcNewRecordReader.java...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/java/org/apache/hadoop/hive/ql/io/orc/SparkOrcNewRecordReader.java...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/java/org/apache/hadoop/hive/ql/io/orc/SparkOrcNewRecordReader.java)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/java/org/apache/hadoop/hive/ql/io/orc/SparkOrcNewRecordReader.java)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/java/org/apache/hadoop/hive/ql/io/orc/SparkOrcNewRecordReader.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, wait, equals, getProgress, getObjectInspector, notifyAll, initialize, getCurrentValue, <init>, nextKeyValue, toString, getCurrentKey, getClass, close, SparkOrcNewRecordReader, value, hashCode.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] Name hashing optimization doesn't apply to non-Scala dependency: /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/java/org/apache/hadoop/hive/ql/io/orc/SparkOrcNewRecordReader.java[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileFormat.scala: Set(getObjectInspector, initialize, <init>, toString, close, SparkOrcNewRecordReader, value)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveFileFormat.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveFileFormat.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveFileFormat.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveFileFormat.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveFileFormat.scala source file has the following implicit definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	typeInfoConversions.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following member ref dependencies of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveFileFormat.scala are invalidated:[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, package, wait, $asInstanceOf, equals, asInstanceOf, synchronized, $isInstanceOf, notifyAll, isInstanceOf, ==, clone, toString, !=, getClass, ne, eq, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveInspectors.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveInspectors.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveInspectors.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Including /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/ScriptTransformationExec.scala by /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveInspectors.scala[0m
[0m[[0mdebug[0m] [0m[naha] Including /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveFileFormat.scala by /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveInspectors.scala[0m
[0m[[0mdebug[0m] [0m[naha] Including /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/TableReader.scala by /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveInspectors.scala[0m
[0m[[0mdebug[0m] [0m[naha] Including /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileFormat.scala by /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveInspectors.scala[0m
[0m[[0mdebug[0m] [0m[naha] Including /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/hiveUDFs.scala by /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveInspectors.scala[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveInspectors.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/ScriptTransformationExec.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveFileFormat.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/TableReader.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileFormat.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/hiveUDFs.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveInspectors.scala source file has the following implicit definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	typeInfoConversions.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following member ref dependencies of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveInspectors.scala are invalidated:[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/TableReader.scala[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveFileFormat.scala[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/ScriptTransformationExec.scala[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/hiveUDFs.scala[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileFormat.scala[0m
[0m[[0mdebug[0m] [0m[naha] The following member ref dependencies of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/ScriptTransformationExec.scala are invalidated:[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala[0m
[0m[[0mdebug[0m] [0m[naha] The following member ref dependencies of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveFileFormat.scala are invalidated:[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala[0m
[0m[[0mdebug[0m] [0m[naha] The following member ref dependencies of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/TableReader.scala are invalidated:[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveFileFormat.scala[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveTableScanExec.scala[0m
[0m[[0mdebug[0m] [0m[naha] The following member ref dependencies of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/hiveUDFs.scala are invalidated:[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionCatalog.scala[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveShim.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveShim.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveShim.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveShim.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveShim.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, getDriverResults, wait, Shim_v0_14, loadPartition, throwExceptionInDropIndex, txnIdInLoadDynamicPartitions, $asInstanceOf, Shim_v2_1, equals, getDataLocation, holdDDLTime, asInstanceOf, initializeLogIfNecessary, setDataLocation, hasFollowingStatsTask, synchronized, $isInstanceOf, Shim_v0_13, getCommandProcessor, findMethod, alterPartitions, logTrace, isTraceEnabled, convertFilters, initializeLogIfNecessary$default$2, Shim_v0_12, isSkewedStoreAsSubdir, Shim_v1_0, getPartitionsByFilter, logName, notifyAll, dropFunction, isInstanceOf, findStaticMethod, alterFunction, getFunctionOption, createFunction, <init>, Shim, ==, clone, setCurrentSessionState, deleteDataInDropIndex, loadTable, $init$, isAcid, Shim_v1_1, environmentContextInAlterTable, toString, dropIndex, renameFunction, logError, !=, alterTable, getClass, logWarning, listFunctions, getMetastoreClientConnectRetryDelayMillis, dropPartition, ne, Shim_v2_0, eq, loadDynamicPartitions, createPartitions, log, Shim_v1_2, ##, finalize, hashCode, getAllPartitions, logDebug, logInfo, dropTable.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala: Set(getDriverResults, Shim_v0_14, loadPartition, Shim_v2_1, getDataLocation, asInstanceOf, synchronized, Shim_v0_13, getCommandProcessor, alterPartitions, Shim_v0_12, Shim_v1_0, getPartitionsByFilter, dropFunction, isInstanceOf, alterFunction, getFunctionOption, createFunction, <init>, ==, setCurrentSessionState, loadTable, Shim_v1_1, toString, dropIndex, renameFunction, logError, !=, alterTable, logWarning, listFunctions, getMetastoreClientConnectRetryDelayMillis, dropPartition, ne, Shim_v2_0, loadDynamicPartitions, createPartitions, Shim_v1_2, logDebug, logInfo, dropTable)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveMetastoreCatalog.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveMetastoreCatalog.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveMetastoreCatalog.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveMetastoreCatalog.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveMetastoreCatalog.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, wait, $asInstanceOf, convertToLogicalRelation, equals, asInstanceOf, initializeLogIfNecessary, synchronized, HiveMetastoreCatalog, $isInstanceOf, logTrace, isTraceEnabled, initializeLogIfNecessary$default$2, logName, notifyAll, isInstanceOf, mergeWithMetastoreSchema, <init>, ==, clone, $init$, getCachedDataSourceTable, toString, logError, !=, getClass, logWarning, ne, eq, log, ##, finalize, hashCode, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionCatalog.scala: Set(asInstanceOf, HiveMetastoreCatalog, isInstanceOf, <init>)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala: Set(asInstanceOf, HiveMetastoreCatalog, <init>)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala: Set(convertToLogicalRelation, asInstanceOf, HiveMetastoreCatalog, isInstanceOf, <init>, ==, toString, logWarning, ne, eq)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/CreateHiveTableAsSelectCommand.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/CreateHiveTableAsSelectCommand.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/CreateHiveTableAsSelectCommand.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/CreateHiveTableAsSelectCommand.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/CreateHiveTableAsSelectCommand.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, treeString$default$2, find, simpleString, children, refresh, maxRowsPerPartition, verboseString, semanticHash, wait, stats, outputColumnNames, copy$default$2, $asInstanceOf, numberedTreeString, printSchema, map, productArity, verboseStringWithSuffix, equals, tableDesc, treeString, schemaString, basicWriteJobStatsTracker, argString, subqueries, asInstanceOf, transformExpressions, initializeLogIfNecessary, run, generateTreeString, outputColumns, childrenResolved, synchronized, generateTreeString$default$6, allAttributes, nodeName, $isInstanceOf, query, validConstraints, logTrace, asCode, canEqual, expressions, canonicalized, copy$default$4, outputSet, isTraceEnabled, makeCopy, initializeLogIfNecessary$default$2, transformUp, productPrefix, resolveChildren, logName, notifyAll, conf, mapProductIterator, collectFirst, otherCopyArgs, missingInput, isInstanceOf, stringArgs, isStreaming, doCanonicalize, collectLeaves, references, <init>, generateTreeString$default$5, foreachUp, mapChildren, schema, transformExpressionsDown, prettyJson, apply, flatMap, resolved, ==, producedAttributes, fastEquals, origin, transformExpressionsUp, clone, constraints, sameResult, foreach, p, jsonFields, resolve, $init$, copy$default$3, copy, mode, inputSet, toString, isCanonicalizedPlan, metrics, logError, !=, statsCache, maxRows, innerChildren, collect, invalidateStatsCache, getClass, logWarning, output, copy$default$1, transformDown, CreateHiveTableAsSelectCommand, transformAllExpressions, mapExpressions, ne, transform, withNewChildren, resolveQuoted, statePrefix, eq, productIterator, toJSON, log, ##, containsChild, finalize, productElement, hashCode, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala: Set(stats, map, tableDesc, asInstanceOf, query, expressions, transformUp, conf, isInstanceOf, references, <init>, schema, apply, resolved, ==, mode, toString, logWarning, output, CreateHiveTableAsSelectCommand, ne, eq)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileFormat.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileFormat.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileFormat.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileFormat.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileFormat.scala source file has the following implicit definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	typeInfoConversions.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Including /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala by /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	customOperatorOptimizationRules, resourceLoader, notify, customCheckRules, listenerManager, loadResource, optimizer, catalog, wait, analyzer, $asInstanceOf, addJar, equals, parentState, asInstanceOf, synchronized, customPostHocResolutionRules, $isInstanceOf, newBuilder, build, customPlanningStrategies, udfRegistration, notifyAll, conf, isInstanceOf, extensions, mergeSparkConf, sqlParser, <init>, ==, clone, HiveSessionResourceLoader, createQueryExecution, HiveSessionStateBuilder, session, functionRegistry, planner, toString, !=, NewBuilder, getClass, customResolutionRules, streamingQueryManager, ne, eq, experimentalMethods, createClone, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala: Set(catalog, analyzer, asInstanceOf, build, conf, isInstanceOf, sqlParser, <init>, ==, HiveSessionStateBuilder, session, toString, NewBuilder, ne, eq)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFilters.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFilters.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFilters.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFilters.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFilters.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, wait, $asInstanceOf, equals, asInstanceOf, initializeLogIfNecessary, synchronized, $isInstanceOf, logTrace, isTraceEnabled, initializeLogIfNecessary$default$2, logName, notifyAll, isInstanceOf, ==, OrcFilters, clone, $init$, toString, createFilter, logError, !=, getClass, logWarning, ne, eq, log, ##, finalize, hashCode, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileFormat.scala: Set(asInstanceOf, isInstanceOf, ==, OrcFilters, toString, createFilter, ne)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionCatalog.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionCatalog.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionCatalog.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionCatalog.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionCatalog.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, databaseExists, metastoreCatalog, renamePartitions, listTables, invalidateAllCachedTables, wait, loadPartition, $asInstanceOf, registerFunction$default$3, getGlobalTempView, listPartitions$default$2, equals, lookupFunction, copyStateTo, getTableMetadata, defaultTablePath, asInstanceOf, initializeLogIfNecessary, isTemporaryFunction, alterDatabase, dropDatabase, alterTempViewDefinition, synchronized, listPartitionNames$default$2, clearTempTables, $isInstanceOf, invalidateCachedTable, externalCatalog, alterPartitions, renameTable, logTrace, isTraceEnabled, initializeLogIfNecessary$default$2, lookupFunctionInfo, listPartitionNames, getDatabaseMetadata, tableExists, logName, getTempViewOrPermanentTableMetadata, notifyAll, dropPartitions, alterTableStats, dropFunction, createDatabase, isInstanceOf, getCachedTable, loadFunctionResources, makeFunctionExpression, createTable, setCurrentDatabase, alterFunction, refreshTable, createGlobalTempView, createFunction, <init>, tempViews, dropTempView, functionExists, getTempView, registerFunction, cacheTable, getCurrentDatabase, createTempView, ==, clone, dropTempFunction, dropGlobalTempView, loadTable, $init$, HiveSessionCatalog, getFunctionMetadata, reset, toString, currentDb, alterTableDataSchema, logError, !=, listPartitions, alterTable, getClass, formatDatabaseName, logWarning, getPartition, listFunctions, formatTableName, getCachedPlan, ne, listPartitionsByFilter, listDatabases, isTemporaryTable, eq, createPartitions, log, ##, finalize, lookupRelation, getDefaultDBPath, hashCode, logDebug, failFunctionLookup, logInfo, dropTable.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala: Set(copyStateTo, asInstanceOf, externalCatalog, <init>, HiveSessionCatalog)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala: Set(metastoreCatalog, asInstanceOf, isInstanceOf, <init>, ==, HiveSessionCatalog, toString, logWarning, ne, eq)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Including /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveTable.scala by /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala[0m
[0m[[0mdebug[0m] [0m[naha] Including /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveDirCommand.scala by /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveDirCommand.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveTable.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, treeString$default$2, find, simpleString, children, refresh, maxRowsPerPartition, verboseString, semanticHash, wait, stats, outputColumnNames, $asInstanceOf, numberedTreeString, printSchema, deleteExternalTmpPath, map, productArity, verboseStringWithSuffix, equals, treeString, schemaString, basicWriteJobStatsTracker, argString, subqueries, asInstanceOf, transformExpressions, initializeLogIfNecessary, run, generateTreeString, outputColumns, childrenResolved, SaveAsHiveFile, synchronized, generateTreeString$default$6, allAttributes, nodeName, $isInstanceOf, query, validConstraints, logTrace, asCode, canEqual, expressions, canonicalized, outputSet, isTraceEnabled, makeCopy, initializeLogIfNecessary$default$2, transformUp, createdTempDir, productPrefix, resolveChildren, logName, notifyAll, conf, mapProductIterator, collectFirst, otherCopyArgs, missingInput, isInstanceOf, stringArgs, saveAsHiveFile, isStreaming, doCanonicalize, collectLeaves, references, generateTreeString$default$5, foreachUp, mapChildren, schema, transformExpressionsDown, prettyJson, apply, flatMap, resolved, ==, producedAttributes, fastEquals, origin, transformExpressionsUp, clone, constraints, sameResult, foreach, p, jsonFields, resolve, $init$, saveAsHiveFile$default$7, inputSet, toString, isCanonicalizedPlan, metrics, logError, !=, statsCache, maxRows, innerChildren, collect, invalidateStatsCache, getClass, logWarning, output, transformDown, transformAllExpressions, mapExpressions, ne, transform, withNewChildren, getExternalTmpPath, resolveQuoted, statePrefix, eq, productIterator, toJSON, log, ##, containsChild, finalize, saveAsHiveFile$default$6, productElement, hashCode, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala: Set(stats, map, asInstanceOf, query, expressions, transformUp, conf, isInstanceOf, references, schema, apply, resolved, ==, toString, logWarning, output, ne, eq)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveTable.scala: Set(outputColumnNames, deleteExternalTmpPath, map, asInstanceOf, SaveAsHiveFile, query, expressions, conf, isInstanceOf, saveAsHiveFile, apply, ==, foreach, resolve, toString, !=, logWarning, output, ne, getExternalTmpPath, eq)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveDirCommand.scala: Set(outputColumnNames, deleteExternalTmpPath, asInstanceOf, outputColumns, SaveAsHiveFile, query, expressions, createdTempDir, isInstanceOf, saveAsHiveFile, apply, ==, foreach, toString, !=, getExternalTmpPath, eq)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala: Set(stats, map, asInstanceOf, query, expressions, transformUp, conf, isInstanceOf, references, schema, apply, resolved, ==, toString, logWarning, output, ne, eq)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/CreateHiveTableAsSelectCommand.scala: Set(outputColumnNames, map, asInstanceOf, run, outputColumns, query, expressions, isInstanceOf, schema, ==, toString, !=, eq)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveOptions.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveOptions.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveOptions.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveOptions.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveOptions.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, wait, $asInstanceOf, containsDelimiters, equals, serde, asInstanceOf, synchronized, $isInstanceOf, notifyAll, SERDE, isInstanceOf, <init>, ==, outputFormat, clone, FILE_FORMAT, serdeProperties, getHiveWriteCompression, toString, !=, INPUT_FORMAT, inputFormat, OUTPUT_FORMAT, getClass, hasInputOutputFormat, ne, HiveOptions, delimiterOptions, eq, ##, finalize, hashCode, fileFormat.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala: Set(asInstanceOf, <init>, ==, getHiveWriteCompression, toString, ne, HiveOptions)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala: Set(serde, asInstanceOf, isInstanceOf, <init>, ==, outputFormat, serdeProperties, toString, inputFormat, hasInputOutputFormat, ne, HiveOptions, eq, fileFormat)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Including /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala by /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala[0m
[0m[[0mdebug[0m] [0m[naha] Including /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala by /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, ruleName, RelationConversions, wait, copy$default$2, $asInstanceOf, Scripts, productArity, equals, asInstanceOf, initializeLogIfNecessary, synchronized, $isInstanceOf, HiveStrategies, logTrace, canEqual, isTraceEnabled, initializeLogIfNecessary$default$2, productPrefix, logName, notifyAll, conf, HiveTableScans, isInstanceOf, <init>, apply, ResolveHiveSerdeTable, ==, clone, DetermineTableStats, planLater, sparkSession, $init$, copy, toString, logError, !=, getClass, logWarning, copy$default$1, ne, HiveAnalysis, sessionCatalog, eq, productIterator, log, ##, finalize, productElement, hashCode, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala: Set(asInstanceOf, conf, isInstanceOf, <init>, apply, ==, sparkSession, toString, logError, ne, eq, log, logDebug)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala: Set(RelationConversions, Scripts, asInstanceOf, HiveStrategies, conf, HiveTableScans, <init>, apply, ResolveHiveSerdeTable, DetermineTableStats, sparkSession, HiveAnalysis)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, getConf, setError, databaseExists, getPartitionNames, getTableOption, renamePartitions, listTables, wait, fromHiveColumn, loadPartition, $asInstanceOf, addJar, state, equals, getDatabase, setInfo, asInstanceOf, initializeLogIfNecessary, alterDatabase, dropDatabase, toHiveTable, synchronized, $isInstanceOf, fromHivePartition, alterPartitions, clientLoader, toHiveTable$default$2, logTrace, isTraceEnabled, initializeLogIfNecessary$default$2, getPartitionsByFilter, tableExists, logName, notifyAll, conf, runHive$default$2, dropPartitions, runHive, dropFunction, createDatabase, isInstanceOf, getState, withHiveState, createTable, setCurrentDatabase, alterFunction, toHivePartition, newSession, version, getPartitionNames$default$2, getFunctionOption, createFunction, <init>, functionExists, toHiveColumn, getPartitions$default$2, ==, clone, getTable, loadTable, $init$, setOut, reset, toString, renameFunction, alterTableDataSchema, logError, !=, getPartitionOption, getFunction, alterTable, getClass, logWarning, getPartitions, runSqlHive, getPartition, listFunctions, ne, listDatabases, HiveClientImpl, eq, loadDynamicPartitions, createPartitions, log, ##, finalize, hashCode, logDebug, logInfo, dropTable.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveDirCommand.scala: Set(asInstanceOf, toHiveTable, isInstanceOf, <init>, ==, toString, !=, HiveClientImpl, eq)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/IsolatedClientLoader.scala: Set(asInstanceOf, synchronized, conf, isInstanceOf, version, <init>, ==, logWarning, ne, HiveClientImpl, hashCode, logDebug, logInfo)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveTable.scala: Set(loadPartition, asInstanceOf, toHiveTable, conf, isInstanceOf, <init>, ==, loadTable, toString, !=, getPartitionOption, logWarning, ne, HiveClientImpl, eq, loadDynamicPartitions)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveTableScanExec.scala: Set(asInstanceOf, toHiveTable, conf, isInstanceOf, toHivePartition, <init>, ==, toString, ne, HiveClientImpl, eq)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveUtils.scala: Set(getConf, fromHiveColumn, state, asInstanceOf, toHiveTable, conf, isInstanceOf, <init>, ==, toString, !=, getClass, logWarning, ne, HiveClientImpl, logInfo)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveTableScanExec.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveTableScanExec.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveTableScanExec.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveTableScanExec.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveTableScanExec.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	newNaturalAscendingOrdering, notify, treeString$default$2, find, simpleString, children, verboseString, semanticHash, execute, executeCollectIterator, wait, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, relation, resetMetrics, printSchema, map, productArity, verboseStringWithSuffix, equals, treeString, schemaString, argString, subqueries, executeQuery, asInstanceOf, transformExpressions, initializeLogIfNecessary, doExecute, HiveTableScanExec, generateTreeString, prepare, synchronized, generateTreeString$default$6, allAttributes, nodeName, $isInstanceOf, doPrepare, requestedAttributes, logTrace, asCode, canEqual, expressions, canonicalized, outputSet, isTraceEnabled, makeCopy, initializeLogIfNecessary$default$2, transformUp, productPrefix, logName, notifyAll, conf, mapProductIterator, collectFirst, otherCopyArgs, missingInput, isInstanceOf, stringArgs, doCanonicalize, collectLeaves, references, newMutableProjection$default$3, <init>, outputOrdering, generateTreeString$default$5, foreachUp, mapChildren, cast, schema, transformExpressionsDown, prettyJson, apply, flatMap, executeCollect, ==, producedAttributes, fastEquals, sqlContext, origin, transformExpressionsUp, clone, rawPartitions, newMutableProjection, newPredicate, sameResult, foreach, p, jsonFields, subexpressionEliminationEnabled, sparkContext, outputPartitioning, $init$, copy$default$3, copy, executeCollectPublic, inputSet, prepareSubqueries, toString, isCanonicalizedPlan, metrics, executeTake, logError, !=, partitionPruningPred, innerChildren, collect, getClass, prunePartitions, longMetric, logWarning, output, copy$default$1, transformDown, transformAllExpressions, mapExpressions, executeBroadcast, ne, requiredChildOrdering, transform, withNewChildren, statePrefix, eq, waitForSubqueries, productIterator, toJSON, log, doExecuteBroadcast, executeToIterator, ##, containsChild, newOrdering, finalize, productElement, hashCode, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala: Set(relation, map, asInstanceOf, HiveTableScanExec, expressions, transformUp, conf, isInstanceOf, references, <init>, schema, apply, ==, toString, logWarning, output, ne, eq)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveDirCommand.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveDirCommand.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveDirCommand.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveDirCommand.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveDirCommand.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, treeString$default$2, find, isLocal, simpleString, children, refresh, maxRowsPerPartition, verboseString, semanticHash, wait, stats, outputColumnNames, copy$default$2, $asInstanceOf, numberedTreeString, copy$default$5, printSchema, deleteExternalTmpPath, map, productArity, verboseStringWithSuffix, equals, treeString, schemaString, basicWriteJobStatsTracker, argString, subqueries, asInstanceOf, InsertIntoHiveDirCommand, transformExpressions, initializeLogIfNecessary, run, generateTreeString, outputColumns, childrenResolved, synchronized, generateTreeString$default$6, allAttributes, nodeName, $isInstanceOf, query, validConstraints, logTrace, asCode, canEqual, expressions, canonicalized, copy$default$4, outputSet, isTraceEnabled, makeCopy, initializeLogIfNecessary$default$2, transformUp, createdTempDir, productPrefix, resolveChildren, logName, notifyAll, conf, mapProductIterator, collectFirst, otherCopyArgs, missingInput, isInstanceOf, stringArgs, saveAsHiveFile, isStreaming, doCanonicalize, collectLeaves, references, <init>, generateTreeString$default$5, foreachUp, mapChildren, schema, transformExpressionsDown, prettyJson, apply, flatMap, resolved, ==, producedAttributes, fastEquals, origin, transformExpressionsUp, clone, constraints, sameResult, foreach, p, jsonFields, resolve, $init$, saveAsHiveFile$default$7, copy$default$3, copy, inputSet, storage, toString, isCanonicalizedPlan, metrics, logError, !=, statsCache, maxRows, innerChildren, collect, invalidateStatsCache, getClass, logWarning, output, copy$default$1, overwrite, transformDown, transformAllExpressions, mapExpressions, ne, transform, withNewChildren, getExternalTmpPath, resolveQuoted, statePrefix, eq, productIterator, toJSON, log, ##, containsChild, finalize, saveAsHiveFile$default$6, productElement, hashCode, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala: Set(isLocal, stats, map, asInstanceOf, InsertIntoHiveDirCommand, query, expressions, transformUp, conf, isInstanceOf, references, <init>, schema, apply, resolved, ==, storage, toString, logWarning, output, overwrite, ne, eq)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveUtils.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveUtils.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveUtils.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveUtils.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveUtils.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, toHiveString, withHiveExternalCatalog, isCliSessionState, newClientForMetadata, wait, $asInstanceOf, HIVE_METASTORE_VERSION, equals, asInstanceOf, initializeLogIfNecessary, HiveUtils, synchronized, HIVE_METASTORE_SHARED_PREFIXES, $isInstanceOf, CONVERT_METASTORE_PARQUET_WITH_SCHEMA_MERGING, HIVE_THRIFT_SERVER_ASYNC, logTrace, isTraceEnabled, initializeLogIfNecessary$default$2, inferSchema, builtinHiveVersion, logName, notifyAll, isInstanceOf, newClientForExecution, primitiveTypes, newTemporaryConfiguration, ==, clone, CONVERT_METASTORE_ORC, $init$, formatTimeVarsForHiveClient, toString, logError, !=, CONVERT_METASTORE_PARQUET, getClass, logWarning, toHiveStructString, ne, HIVE_METASTORE_BARRIER_PREFIXES, HIVE_METASTORE_JARS, eq, log, ##, finalize, hashCode, FAKE_HIVE_VERSION, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/IsolatedClientLoader.scala: Set(asInstanceOf, HiveUtils, synchronized, isInstanceOf, ==, logWarning, ne, HIVE_METASTORE_JARS, hashCode, logDebug, logInfo)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveExternalCatalog.scala: Set(newClientForMetadata, asInstanceOf, HiveUtils, synchronized, isInstanceOf, ==, toString, !=, getClass, logWarning, ne, logInfo)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala: Set(withHiveExternalCatalog, HiveUtils)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala: Set(asInstanceOf, HiveUtils, CONVERT_METASTORE_PARQUET_WITH_SCHEMA_MERGING, inferSchema, isInstanceOf, ==, CONVERT_METASTORE_ORC, toString, CONVERT_METASTORE_PARQUET, logWarning, ne, eq)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala: Set(withHiveExternalCatalog, newClientForMetadata, asInstanceOf, HiveUtils, isInstanceOf, newTemporaryConfiguration, ==, toString, logError, ne, eq, log, logDebug)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala source file has the following implicit definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	newByteEncoder, newScalaDecimalEncoder, newBoxedDoubleEncoder, newBoxedFloatEncoder, newByteArrayEncoder, newIntArrayEncoder, newBooleanArrayEncoder, newFloatEncoder, newMapEncoder, newProductEncoder, newDoubleArrayEncoder, newBoxedLongEncoder, newBoxedShortEncoder, newSequenceEncoder, newIntEncoder, newShortArrayEncoder, newJavaDecimalEncoder, newStringEncoder, newBooleanEncoder, StringToColumn, newLongArrayEncoder, newShortEncoder, newFloatArrayEncoder, newBoxedIntEncoder, localSeqToDatasetHolder, newBoxedBooleanEncoder, newDoubleEncoder, newTimeStampEncoder, symbolToColumn, newLongEncoder, newDateEncoder, newProductArrayEncoder, rddToDatasetHolder, newBoxedByteEncoder, newSetEncoder, newStringArrayEncoder.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/ScriptTransformationExec.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/ScriptTransformationExec.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/ScriptTransformationExec.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/ScriptTransformationExec.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/ScriptTransformationExec.scala source file has the following implicit definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	typeInfoConversions.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following member ref dependencies of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/ScriptTransformationExec.scala are invalidated:[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package-info.java...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package-info.java...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package-info.java)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package-info.java)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/package-info.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/TableReader.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/TableReader.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/TableReader.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/TableReader.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/TableReader.scala source file has the following implicit definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	typeInfoConversions.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following member ref dependencies of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/TableReader.scala are invalidated:[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveFileFormat.scala[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveTableScanExec.scala[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClient.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClient.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClient.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Including /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala by /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClient.scala[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClient.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClient.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, getConf, setError, databaseExists, getPartitionNames, getTableOption, renamePartitions, listTables, wait, loadPartition, HiveClient, $asInstanceOf, addJar, equals, getDatabase, setInfo, asInstanceOf, alterDatabase, dropDatabase, synchronized, $isInstanceOf, alterPartitions, getPartitionsByFilter, tableExists, notifyAll, dropPartitions, dropFunction, createDatabase, isInstanceOf, getState, withHiveState, createTable, setCurrentDatabase, alterFunction, newSession, version, getPartitionNames$default$2, getFunctionOption, createFunction, functionExists, getPartitions$default$2, ==, clone, getTable, loadTable, $init$, setOut, reset, toString, renameFunction, alterTableDataSchema, !=, getPartitionOption, getFunction, alterTable, getClass, getPartitions, runSqlHive, getPartition, listFunctions, ne, listDatabases, eq, loadDynamicPartitions, createPartitions, ##, finalize, hashCode, dropTable.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/IsolatedClientLoader.scala: Set(HiveClient, asInstanceOf, synchronized, isInstanceOf, version, ==, ne, hashCode)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveExternalCatalog.scala: Set(databaseExists, getPartitionNames, renamePartitions, listTables, loadPartition, HiveClient, getDatabase, asInstanceOf, alterDatabase, dropDatabase, synchronized, alterPartitions, getPartitionsByFilter, tableExists, dropPartitions, dropFunction, createDatabase, isInstanceOf, createTable, setCurrentDatabase, alterFunction, version, createFunction, functionExists, ==, getTable, loadTable, toString, renameFunction, alterTableDataSchema, !=, getPartitionOption, getFunction, alterTable, getClass, getPartitions, getPartition, listFunctions, ne, listDatabases, loadDynamicPartitions, createPartitions, dropTable)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala: Set(HiveClient, addJar, asInstanceOf)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala: Set(getConf, databaseExists, getPartitionNames, loadPartition, HiveClient, addJar, getDatabase, asInstanceOf, alterDatabase, dropDatabase, synchronized, alterPartitions, getPartitionsByFilter, dropFunction, createDatabase, isInstanceOf, withHiveState, createTable, setCurrentDatabase, alterFunction, version, getFunctionOption, createFunction, ==, getTable, loadTable, toString, renameFunction, !=, getPartitionOption, alterTable, getPartitions, runSqlHive, getPartition, listFunctions, ne, loadDynamicPartitions, createPartitions, dropTable)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala: Set(HiveClient, asInstanceOf, version, ==, toString, ne)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveUtils.scala: Set(getConf, HiveClient, asInstanceOf, isInstanceOf, ==, toString, !=, getClass, ne)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala: Set(HiveClient, asInstanceOf, isInstanceOf, setCurrentDatabase, newSession, ==, reset, toString, runSqlHive, ne, eq)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveDirCommand.scala: Set(asInstanceOf, isInstanceOf, ==, toString, !=, eq)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/IsolatedClientLoader.scala: Set(HiveClient, asInstanceOf, synchronized, isInstanceOf, version, ==, ne, hashCode)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveTable.scala: Set(loadPartition, asInstanceOf, isInstanceOf, ==, loadTable, toString, !=, getPartitionOption, ne, eq, loadDynamicPartitions)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveTableScanExec.scala: Set(asInstanceOf, isInstanceOf, ==, toString, ne, eq)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveUtils.scala: Set(getConf, HiveClient, asInstanceOf, isInstanceOf, ==, toString, !=, getClass, ne)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/hiveUDFs.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/hiveUDFs.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/hiveUDFs.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/hiveUDFs.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/hiveUDFs.scala source file has the following implicit definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	typeInfoConversions.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following member ref dependencies of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/hiveUDFs.scala are invalidated:[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionCatalog.scala[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/package.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/package.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/package.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/package.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/package.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, package, v13, fullVersion, wait, $asInstanceOf, v2_0, productArity, equals, v1_1, v2_1, asInstanceOf, HiveVersion, synchronized, $isInstanceOf, v12, canEqual, productPrefix, notifyAll, v1_2, isInstanceOf, <init>$default$3, <init>, ==, clone, hive, extraDeps, $init$, exclusions, toString, !=, v1_0, allSupportedHiveVersions, getClass, ne, v14, <init>$default$2, eq, productIterator, ##, finalize, productElement, hashCode.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/IsolatedClientLoader.scala: Set(package, v13, fullVersion, v2_0, v1_1, v2_1, asInstanceOf, HiveVersion, synchronized, v12, v1_2, isInstanceOf, <init>, ==, hive, extraDeps, exclusions, v1_0, ne, v14, hashCode)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala: Set(package, v13, fullVersion, v2_0, v1_1, v2_1, asInstanceOf, HiveVersion, synchronized, v12, v1_2, isInstanceOf, <init>, ==, hive, toString, !=, v1_0, ne, v14)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClient.scala: Set(package, HiveVersion, <init>, hive)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala: Set(package, v13, fullVersion, v2_0, v1_1, v2_1, asInstanceOf, HiveVersion, v12, v1_2, <init>, ==, hive, toString, v1_0, allSupportedHiveVersions, ne, v14)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveUtils.scala: Set(package, asInstanceOf, HiveVersion, isInstanceOf, <init>, ==, hive, toString, !=, getClass, ne)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveShim.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveShim.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveShim.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveShim.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveShim.scala source file has the following implicit definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	wrapperToFileSinkDesc.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following member ref dependencies of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveShim.scala are invalidated:[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveInspectors.scala[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionCatalog.scala[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/TableReader.scala[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveFileFormat.scala[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/HiveTableScanExec.scala[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveDirCommand.scala[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveTable.scala[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/ScriptTransformationExec.scala[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/hiveUDFs.scala[0m
[0m[[0mdebug[0m] [0m[naha] 	/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileFormat.scala[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/IsolatedClientLoader.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/IsolatedClientLoader.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/IsolatedClientLoader.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/IsolatedClientLoader.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/IsolatedClientLoader.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	createClient, forVersion$default$8, notify, IsolatedClientLoader, isSharedClass, forVersion, wait, <init>$default$5, $asInstanceOf, <init>$default$6, isBarrierClass, addJar, hiveVersion, equals, sharesHadoopClasses, asInstanceOf, initializeLogIfNecessary, rootClassLoader, synchronized, forVersion$default$5, <init>$default$7, $isInstanceOf, <init>$default$4, logTrace, config, hadoopConf, isTraceEnabled, initializeLogIfNecessary$default$2, <init>$default$11, logName, notifyAll, <init>$default$10, isInstanceOf, version, <init>$default$8, sharedPrefixes, allJars, <init>, sparkConf, ==, classLoader, clone, forVersion$default$6, $init$, cachedHive, toString, logError, !=, <init>$default$9, isolationOn, execJars, getClass, logWarning, barrierPrefixes, ne, baseClassLoader, eq, log, classToPath, ##, forVersion$default$7, finalize, hashCode, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala: Set(createClient, IsolatedClientLoader, addJar, asInstanceOf, synchronized, hadoopConf, isInstanceOf, version, <init>, sparkConf, ==, classLoader, cachedHive, toString, logError, !=, isolationOn, logWarning, ne, logDebug, logInfo)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveUtils.scala: Set(createClient, IsolatedClientLoader, forVersion, hiveVersion, asInstanceOf, hadoopConf, isInstanceOf, allJars, <init>, ==, classLoader, toString, !=, getClass, logWarning, ne, logInfo)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileOperator.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileOperator.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileOperator.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileOperator.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileOperator.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, readSchema, OrcFileOperator, wait, getFileReader$default$3, $asInstanceOf, getFileReader$default$2, equals, asInstanceOf, initializeLogIfNecessary, synchronized, $isInstanceOf, getFileReader, logTrace, isTraceEnabled, initializeLogIfNecessary$default$2, getObjectInspector, logName, notifyAll, isInstanceOf, ==, clone, $init$, toString, logError, !=, getClass, logWarning, ne, eq, listOrcFiles, log, ##, finalize, hashCode, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/orc/OrcFileFormat.scala: Set(readSchema, OrcFileOperator, asInstanceOf, getObjectInspector, isInstanceOf, ==, toString, ne)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala source file has the following implicit definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	newByteEncoder, newScalaDecimalEncoder, newBoxedDoubleEncoder, newBoxedFloatEncoder, newByteArrayEncoder, newIntArrayEncoder, newBooleanArrayEncoder, newFloatEncoder, newMapEncoder, newProductEncoder, newDoubleArrayEncoder, newBoxedLongEncoder, newBoxedShortEncoder, newSequenceEncoder, newIntEncoder, newShortArrayEncoder, newJavaDecimalEncoder, newStringEncoder, newBooleanEncoder, StringToColumn, newLongArrayEncoder, newShortEncoder, newFloatArrayEncoder, newBoxedIntEncoder, localSeqToDatasetHolder, newBoxedBooleanEncoder, newDoubleEncoder, newTimeStampEncoder, symbolToColumn, newLongEncoder, newDateEncoder, newProductArrayEncoder, rddToDatasetHolder, SqlCmd, newBoxedByteEncoder, newSetEncoder, newStringArrayEncoder.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveExternalCatalog.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveExternalCatalog.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveExternalCatalog.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Including /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala by /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveExternalCatalog.scala[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveExternalCatalog.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveExternalCatalog.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, HiveExternalCatalog, databaseExists, getTimer, postToAll, STATISTICS_TOTAL_SIZE, renamePartitions, listTables, STATISTICS_NUM_ROWS, doDropFunction, STATISTICS_PREFIX, wait, loadPartition, $asInstanceOf, DATASOURCE_SCHEMA_NUMPARTS, listeners, doCreateDatabase, equals, STATISTICS_COL_STATS_PREFIX, getDatabase, DATASOURCE_SCHEMA_NUMBUCKETCOLS, asInstanceOf, initializeLogIfNecessary, alterDatabase, dropDatabase, CREATED_SPARK_VERSION, synchronized, SPARK_SQL_PREFIX, doRenameFunction, doDropTable, $isInstanceOf, alterPartitions, doAlterTable, renameTable, logTrace, doDropDatabase, isTraceEnabled, initializeLogIfNecessary$default$2, DATASOURCE_SCHEMA_PARTCOL_PREFIX, DATASOURCE_SCHEMA, DATASOURCE_PREFIX, DATASOURCE_SCHEMA_NUMSORTCOLS, listPartitionNames, tableExists, requireFunctionNotExists, DATASOURCE_SCHEMA_BUCKETCOL_PREFIX, logName, notifyAll, DATASOURCE_PROVIDER, dropPartitions, alterTableStats, TABLE_PARTITION_PROVIDER_CATALOG, dropFunction, createDatabase, isInstanceOf, listPartitionNames$default$3, DATASOURCE_SCHEMA_NUMPARTCOLS, createTable, setCurrentDatabase, alterFunction, TABLE_PARTITION_PROVIDER, requireDbExists, removeListener, createFunction, <init>, doAlterFunction, requireTableExists, functionExists, doCreateFunction, EMPTY_DATA_SCHEMA, requireFunctionExists, ==, DATASOURCE_SCHEMA_PART_PREFIX, DATASOURCE_SCHEMA_NUMBUCKETS, clone, client, doRenameTable, getTable, loadTable, $init$, DATASOURCE_SCHEMA_SORTCOL_PREFIX, findListenersByClass, toString, DATASOURCE_SCHEMA_PREFIX, renameFunction, isDatasourceTable, doCreateTable, getRawTable, alterTableDataSchema, logError, !=, listPartitions, listPartitions$default$3, getPartitionOption, getFunction, alterTable, getClass, logWarning, getPartition, listFunctions, doAlterTableDataSchema, doPostEvent, doAlterDatabase, addListener, ne, TABLE_PARTITION_PROVIDER_FILESYSTEM, listPartitionsByFilter, listDatabases, eq, loadDynamicPartitions, createPartitions, log, ##, finalize, hashCode, logDebug, logInfo, dropTable, doAlterTableStats, removeListenerOnError.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala: Set(HiveExternalCatalog, asInstanceOf, <init>, client)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala: Set(HiveExternalCatalog, databaseExists, loadPartition, DATASOURCE_SCHEMA_NUMPARTS, getDatabase, asInstanceOf, alterDatabase, dropDatabase, synchronized, alterPartitions, DATASOURCE_SCHEMA, dropFunction, createDatabase, isInstanceOf, createTable, setCurrentDatabase, alterFunction, createFunction, <init>, ==, DATASOURCE_SCHEMA_PART_PREFIX, client, getTable, loadTable, toString, renameFunction, logError, !=, getPartitionOption, alterTable, logWarning, getPartition, listFunctions, ne, loadDynamicPartitions, createPartitions, logDebug, logInfo, dropTable)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionCatalog.scala: Set(HiveExternalCatalog, asInstanceOf, isInstanceOf, <init>, functionExists)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/SaveAsHiveFile.scala: Set(HiveExternalCatalog, asInstanceOf, <init>, ==, client, toString, logWarning, ne, logDebug)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/test/TestHive.scala: Set(HiveExternalCatalog, asInstanceOf, isInstanceOf, setCurrentDatabase, <init>, ==, client, toString, logError, ne, eq, log, logDebug)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveTable.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveTable.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveTable.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveTable.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveTable.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, treeString$default$2, find, simpleString, children, refresh, maxRowsPerPartition, verboseString, semanticHash, wait, stats, outputColumnNames, copy$default$2, $asInstanceOf, ifPartitionNotExists, numberedTreeString, copy$default$5, printSchema, deleteExternalTmpPath, map, productArity, verboseStringWithSuffix, equals, treeString, schemaString, basicWriteJobStatsTracker, argString, subqueries, asInstanceOf, transformExpressions, initializeLogIfNecessary, run, generateTreeString, outputColumns, childrenResolved, synchronized, generateTreeString$default$6, partition, allAttributes, nodeName, $isInstanceOf, InsertIntoHiveTable, query, validConstraints, logTrace, asCode, canEqual, expressions, canonicalized, copy$default$4, outputSet, isTraceEnabled, makeCopy, initializeLogIfNecessary$default$2, transformUp, createdTempDir, productPrefix, resolveChildren, logName, notifyAll, conf, mapProductIterator, collectFirst, otherCopyArgs, missingInput, isInstanceOf, stringArgs, saveAsHiveFile, isStreaming, doCanonicalize, collectLeaves, references, <init>, generateTreeString$default$5, foreachUp, mapChildren, schema, transformExpressionsDown, prettyJson, apply, flatMap, resolved, ==, producedAttributes, fastEquals, origin, transformExpressionsUp, clone, constraints, sameResult, foreach, p, jsonFields, resolve, $init$, saveAsHiveFile$default$7, copy$default$3, copy, inputSet, toString, isCanonicalizedPlan, metrics, logError, !=, statsCache, maxRows, innerChildren, collect, invalidateStatsCache, getClass, logWarning, output, copy$default$1, overwrite, transformDown, transformAllExpressions, mapExpressions, copy$default$6, ne, transform, withNewChildren, getExternalTmpPath, resolveQuoted, statePrefix, eq, productIterator, toJSON, log, ##, containsChild, finalize, table, saveAsHiveFile$default$6, productElement, hashCode, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveStrategies.scala: Set(stats, ifPartitionNotExists, map, asInstanceOf, partition, InsertIntoHiveTable, query, expressions, transformUp, conf, isInstanceOf, references, <init>, schema, apply, resolved, ==, toString, logWarning, output, overwrite, ne, eq, table)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/CreateHiveTableAsSelectCommand.scala: Set(outputColumnNames, map, asInstanceOf, run, outputColumns, partition, InsertIntoHiveTable, query, expressions, isInstanceOf, <init>, schema, ==, toString, !=, eq, table)[0m
[0m[[0mdebug[0m] [0m[naha] New invalidations:[0m
[0m[[0mdebug[0m] [0m[naha] 	Set()[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set()[0m
[0m[[0mdebug[0m] [0m[naha] Previously invalidated, but (transitively) depend on new invalidations:[0m
[0m[[0mdebug[0m] [0m[naha] 	Set()[0m
[0m[[0mdebug[0m] [0m[naha] All newly invalidated sources after taking into account (previously) recompiled sources:Set()[0m
