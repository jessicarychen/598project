[0m[[0mdebug[0m] [0m[naha] [0m
[0m[[0mdebug[0m] [0m[naha] Initial source changes: [0m
[0m[[0mdebug[0m] [0m[naha] 	removed:Set()[0m
[0m[[0mdebug[0m] [0m[naha] 	added: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaContinuousReader.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriteTask.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/CachedKafkaProducer.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaRelation.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/ConsumerStrategy.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSink.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetRangeLimit.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaDataConsumer.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/package-info.java, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/JsonUtils.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaStreamWriter.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetReader.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriter.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSource.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceOffset.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceRDD.scala)[0m
[0m[[0mdebug[0m] [0m[naha] 	modified: Set()[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated products: Set()[0m
[0m[[0mdebug[0m] [0m[naha] External API changes: API Changes: Set()[0m
[0m[[0mdebug[0m] [0m[naha] Modified binary dependencies: Set()[0m
[0m[[0mdebug[0m] [0m[naha] Initial directly invalidated sources: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaContinuousReader.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriteTask.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/CachedKafkaProducer.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaRelation.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/ConsumerStrategy.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSink.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetRangeLimit.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaDataConsumer.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/package-info.java, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/JsonUtils.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaStreamWriter.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetReader.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriter.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSource.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceOffset.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceRDD.scala)[0m
[0m[[0mdebug[0m] [0m[naha] [0m
[0m[[0mdebug[0m] [0m[naha] Sources indirectly invalidated by:[0m
[0m[[0mdebug[0m] [0m[naha] 	product: Set()[0m
[0m[[0mdebug[0m] [0m[naha] 	binary dep: Set()[0m
[0m[[0mdebug[0m] [0m[naha] 	external source: Set()[0m
[0m[[0mdebug[0m] [0mAll initially invalidated sources: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaContinuousReader.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriteTask.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/CachedKafkaProducer.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaRelation.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/ConsumerStrategy.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSink.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetRangeLimit.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaDataConsumer.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/package-info.java, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/JsonUtils.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaStreamWriter.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetReader.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriter.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSource.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceOffset.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceRDD.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaContinuousReader.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriteTask.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/CachedKafkaProducer.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaRelation.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/ConsumerStrategy.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSink.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetRangeLimit.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaDataConsumer.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/package-info.java, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/JsonUtils.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaStreamWriter.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetReader.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriter.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSource.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceOffset.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceRDD.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Recompiling all 17 sources: invalidated sources (17) exceeded 50.0% of all sources[0m
[0m[[0minfo[0m] [0mCompiling 16 Scala sources and 1 Java source to /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/target/scala-2.11/classes...[0m
[0m[[0mdebug[0m] [0mGetting org.scala-sbt:compiler-interface:0.13.16:component from component compiler for Scala 2.11.8[0m
[0m[[0mdebug[0m] [0mGetting org.scala-sbt:compiler-interface:0.13.16:component from component compiler for Scala 2.11.8[0m
[0m[[0mdebug[0m] [0mRunning cached compiler 2ebed850, interfacing (CompilerInterface) with Scala compiler version 2.11.8[0m
[0m[[0mdebug[0m] [0mCalling Scala compiler with arguments  (CompilerInterface):[0m
[0m[[0mdebug[0m] [0m	-unchecked[0m
[0m[[0mdebug[0m] [0m	-deprecation[0m
[0m[[0mdebug[0m] [0m	-feature[0m
[0m[[0mdebug[0m] [0m	-explaintypes[0m
[0m[[0mdebug[0m] [0m	-Yno-adapted-args[0m
[0m[[0mdebug[0m] [0m	-P:genjavadoc:out=/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/target/java[0m
[0m[[0mdebug[0m] [0m	-P:genjavadoc:strictVisibility=true[0m
[0m[[0mdebug[0m] [0m	-Xplugin:/home/vm1/.ivy2/cache/com.typesafe.genjavadoc/genjavadoc-plugin_2.11.8/jars/genjavadoc-plugin_2.11.8-0.10.jar[0m
[0m[[0mdebug[0m] [0m	-target:jvm-1.8[0m
[0m[[0mdebug[0m] [0m	-sourcepath[0m
[0m[[0mdebug[0m] [0m	/usr/local/spark-2.3.2-bin-hadoop2.7[0m
[0m[[0mdebug[0m] [0m	-bootclasspath[0m
[0m[[0mdebug[0m] [0m	/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes:/home/vm1/.ivy2/cache/org.scala-lang/scala-library/jars/scala-library-2.11.8.jar[0m
[0m[[0mdebug[0m] [0m	-classpath[0m
[0m[[0mdebug[0m] [0m	/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/target/scala-2.11/classes:/usr/local/spark-2.3.2-bin-hadoop2.7/sql/core/target/scala-2.11/spark-sql_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/common/sketch/target/scala-2.11/spark-sketch_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/common/tags/target/scala-2.11/spark-tags_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/core/target/scala-2.11/spark-core_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/launcher/target/scala-2.11/spark-launcher_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/common/kvstore/target/scala-2.11/spark-kvstore_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/common/network-common/target/scala-2.11/spark-network-common_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/common/network-shuffle/target/scala-2.11/spark-network-shuffle_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/common/unsafe/target/scala-2.11/spark-unsafe_2.11-2.3.2.jar:/usr/local/spark-2.3.2-bin-hadoop2.7/sql/catalyst/target/scala-2.11/spark-catalyst_2.11-2.3.2.jar:/home/vm1/.ivy2/cache/org.spark-project.spark/unused/jars/unused-1.0.0.jar:/home/vm1/.ivy2/cache/com.google.guava/guava/bundles/guava-14.0.1.jar:/home/vm1/.ivy2/cache/org.jpmml/pmml-model/jars/pmml-model-1.2.15.jar:/home/vm1/.ivy2/cache/org.jpmml/pmml-schema/jars/pmml-schema-1.2.15.jar:/home/vm1/.ivy2/cache/org.fusesource.leveldbjni/leveldbjni-all/bundles/leveldbjni-all-1.8.jar:/home/vm1/.ivy2/cache/com.fasterxml.jackson.core/jackson-databind/bundles/jackson-databind-2.6.7.1.jar:/home/vm1/.ivy2/cache/com.fasterxml.jackson.core/jackson-annotations/bundles/jackson-annotations-2.6.7.jar:/home/vm1/.ivy2/cache/io.netty/netty-all/jars/netty-all-4.1.17.Final.jar:/home/vm1/.ivy2/cache/org.apache.commons/commons-lang3/jars/commons-lang3-3.5.jar:/home/vm1/.ivy2/cache/io.dropwizard.metrics/metrics-core/bundles/metrics-core-3.1.5.jar:/home/vm1/.ivy2/cache/org.apache.commons/commons-crypto/jars/commons-crypto-1.0.0.jar:/home/vm1/.ivy2/cache/com.twitter/chill_2.11/jars/chill_2.11-0.8.4.jar:/home/vm1/.ivy2/cache/com.twitter/chill-java/jars/chill-java-0.8.4.jar:/home/vm1/.ivy2/cache/com.esotericsoftware/kryo-shaded/bundles/kryo-shaded-3.0.3.jar:/home/vm1/.ivy2/cache/com.esotericsoftware/minlog/bundles/minlog-1.3.0.jar:/home/vm1/.ivy2/cache/org.objenesis/objenesis/jars/objenesis-2.1.jar:/home/vm1/.ivy2/cache/org.apache.avro/avro/jars/avro-1.7.7.jar:/home/vm1/.ivy2/cache/org.codehaus.jackson/jackson-core-asl/jars/jackson-core-asl-1.9.13.jar:/home/vm1/.ivy2/cache/org.codehaus.jackson/jackson-mapper-asl/jars/jackson-mapper-asl-1.9.13.jar:/home/vm1/.ivy2/cache/org.xerial.snappy/snappy-java/bundles/snappy-java-1.1.2.6.jar:/home/vm1/.ivy2/cache/org.apache.commons/commons-compress/jars/commons-compress-1.4.1.jar:/home/vm1/.ivy2/cache/org.tukaani/xz/jars/xz-1.0.jar:/home/vm1/.ivy2/cache/org.apache.avro/avro-mapred/jars/avro-mapred-1.7.7-hadoop2.jar:/home/vm1/.ivy2/cache/org.apache.avro/avro-ipc/jars/avro-ipc-1.7.7-tests.jar:/home/vm1/.ivy2/cache/org.apache.avro/avro-ipc/jars/avro-ipc-1.7.7.jar:/home/vm1/.ivy2/cache/org.apache.xbean/xbean-asm5-shaded/bundles/xbean-asm5-shaded-4.4.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-client/jars/hadoop-client-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-common/jars/hadoop-common-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-annotations/jars/hadoop-annotations-2.6.5.jar:/home/vm1/.ivy2/cache/commons-cli/commons-cli/jars/commons-cli-1.2.jar:/home/vm1/.ivy2/cache/org.apache.commons/commons-math3/jars/commons-math3-3.4.1.jar:/home/vm1/.ivy2/cache/xmlenc/xmlenc/jars/xmlenc-0.52.jar:/home/vm1/.ivy2/cache/commons-httpclient/commons-httpclient/jars/commons-httpclient-3.1.jar:/home/vm1/.ivy2/cache/commons-io/commons-io/jars/commons-io-2.4.jar:/home/vm1/.ivy2/cache/commons-net/commons-net/jars/commons-net-3.1.jar:/home/vm1/.ivy2/cache/commons-collections/commons-collections/jars/commons-collections-3.2.2.jar:/home/vm1/.ivy2/cache/log4j/log4j/bundles/log4j-1.2.17.jar:/home/vm1/.ivy2/cache/commons-lang/commons-lang/jars/commons-lang-2.6.jar:/home/vm1/.ivy2/cache/commons-configuration/commons-configuration/jars/commons-configuration-1.6.jar:/home/vm1/.ivy2/cache/commons-digester/commons-digester/jars/commons-digester-1.8.jar:/home/vm1/.ivy2/cache/commons-beanutils/commons-beanutils/jars/commons-beanutils-1.7.0.jar:/home/vm1/.ivy2/cache/commons-beanutils/commons-beanutils-core/jars/commons-beanutils-core-1.8.0.jar:/home/vm1/.ivy2/cache/com.google.protobuf/protobuf-java/bundles/protobuf-java-2.5.0.jar:/home/vm1/.ivy2/cache/com.google.code.gson/gson/jars/gson-2.2.4.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-auth/jars/hadoop-auth-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.directory.server/apacheds-kerberos-codec/bundles/apacheds-kerberos-codec-2.0.0-M15.jar:/home/vm1/.ivy2/cache/org.apache.directory.server/apacheds-i18n/bundles/apacheds-i18n-2.0.0-M15.jar:/home/vm1/.ivy2/cache/org.apache.directory.api/api-asn1-api/bundles/api-asn1-api-1.0.0-M20.jar:/home/vm1/.ivy2/cache/org.apache.directory.api/api-util/bundles/api-util-1.0.0-M20.jar:/home/vm1/.ivy2/cache/org.apache.curator/curator-framework/bundles/curator-framework-2.6.0.jar:/home/vm1/.ivy2/cache/org.apache.curator/curator-client/bundles/curator-client-2.6.0.jar:/home/vm1/.ivy2/cache/org.apache.zookeeper/zookeeper/jars/zookeeper-3.4.6.jar:/home/vm1/.ivy2/cache/jline/jline/jars/jline-0.9.94.jar:/home/vm1/.ivy2/cache/io.netty/netty/bundles/netty-3.9.9.Final.jar:/home/vm1/.ivy2/cache/org.apache.curator/curator-recipes/bundles/curator-recipes-2.6.0.jar:/home/vm1/.ivy2/cache/org.htrace/htrace-core/jars/htrace-core-3.0.4.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-hdfs/jars/hadoop-hdfs-2.6.5.jar:/home/vm1/.ivy2/cache/org.mortbay.jetty/jetty-util/jars/jetty-util-6.1.26.jar:/home/vm1/.ivy2/cache/xerces/xercesImpl/jars/xercesImpl-2.9.1.jar:/home/vm1/.ivy2/cache/xml-apis/xml-apis/jars/xml-apis-1.3.04.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-mapreduce-client-app/jars/hadoop-mapreduce-client-app-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-mapreduce-client-common/jars/hadoop-mapreduce-client-common-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-yarn-common/jars/hadoop-yarn-common-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-yarn-api/jars/hadoop-yarn-api-2.6.5.jar:/home/vm1/.ivy2/cache/javax.xml.bind/jaxb-api/jars/jaxb-api-2.2.2.jar:/home/vm1/.ivy2/cache/javax.xml.stream/stax-api/jars/stax-api-1.0-2.jar:/home/vm1/.ivy2/cache/org.codehaus.jackson/jackson-jaxrs/jars/jackson-jaxrs-1.9.13.jar:/home/vm1/.ivy2/cache/org.codehaus.jackson/jackson-xc/jars/jackson-xc-1.9.13.jar:/home/vm1/.ivy2/cache/com.google.inject/guice/jars/guice-3.0.jar:/home/vm1/.ivy2/cache/javax.inject/javax.inject/jars/javax.inject-1.jar:/home/vm1/.ivy2/cache/aopalliance/aopalliance/jars/aopalliance-1.0.jar:/home/vm1/.ivy2/cache/org.sonatype.sisu.inject/cglib/jars/cglib-2.2.1-v20090111.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-yarn-client/jars/hadoop-yarn-client-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-mapreduce-client-core/jars/hadoop-mapreduce-client-core-2.6.5.jar:/home/vm1/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.16.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-yarn-server-common/jars/hadoop-yarn-server-common-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-mapreduce-client-shuffle/jars/hadoop-mapreduce-client-shuffle-2.6.5.jar:/home/vm1/.ivy2/cache/org.apache.hadoop/hadoop-mapreduce-client-jobclient/jars/hadoop-mapreduce-client-jobclient-2.6.5.jar:/home/vm1/.ivy2/cache/org.codehaus.jettison/jettison/bundles/jettison-1.1.jar:/home/vm1/.ivy2/cache/net.java.dev.jets3t/jets3t/jars/jets3t-0.9.4.jar:/home/vm1/.ivy2/cache/org.apache.httpcomponents/httpcore/jars/httpcore-4.4.1.jar:/home/vm1/.ivy2/cache/org.apache.httpcomponents/httpclient/jars/httpclient-4.5.jar:/home/vm1/.ivy2/cache/commons-codec/commons-codec/jars/commons-codec-1.11.jar:/home/vm1/.ivy2/cache/javax.activation/activation/jars/activation-1.1.1.jar:/home/vm1/.ivy2/cache/org.bouncycastle/bcprov-jdk15on/jars/bcprov-jdk15on-1.52.jar:/home/vm1/.ivy2/cache/com.jamesmurty.utils/java-xmlbuilder/jars/java-xmlbuilder-1.1.jar:/home/vm1/.ivy2/cache/net.iharder/base64/jars/base64-2.3.8.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-plus/jars/jetty-plus-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-webapp/jars/jetty-webapp-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-xml/jars/jetty-xml-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-util/jars/jetty-util-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-servlet/jars/jetty-servlet-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-security/jars/jetty-security-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-server/jars/jetty-server-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/javax.servlet/javax.servlet-api/jars/javax.servlet-api-3.1.0.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-http/jars/jetty-http-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-io/jars/jetty-io-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-jndi/jars/jetty-jndi-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-continuation/jars/jetty-continuation-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-proxy/jars/jetty-proxy-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-client/jars/jetty-client-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.eclipse.jetty/jetty-servlets/jars/jetty-servlets-9.3.24.v20180605.jar:/home/vm1/.ivy2/cache/org.slf4j/jul-to-slf4j/jars/jul-to-slf4j-1.7.16.jar:/home/vm1/.ivy2/cache/org.slf4j/jcl-over-slf4j/jars/jcl-over-slf4j-1.7.16.jar:/home/vm1/.ivy2/cache/com.ning/compress-lzf/bundles/compress-lzf-1.0.3.jar:/home/vm1/.ivy2/cache/org.lz4/lz4-java/jars/lz4-java-1.4.0.jar:/home/vm1/.ivy2/cache/com.github.luben/zstd-jni/bundles/zstd-jni-1.3.2-2.jar:/home/vm1/.ivy2/cache/org.roaringbitmap/RoaringBitmap/bundles/RoaringBitmap-0.5.11.jar:/home/vm1/.ivy2/cache/org.json4s/json4s-jackson_2.11/jars/json4s-jackson_2.11-3.2.11.jar:/home/vm1/.ivy2/cache/org.json4s/json4s-core_2.11/jars/json4s-core_2.11-3.2.11.jar:/home/vm1/.ivy2/cache/org.json4s/json4s-ast_2.11/jars/json4s-ast_2.11-3.2.11.jar:/home/vm1/.ivy2/cache/org.scala-lang/scalap/jars/scalap-2.11.8.jar:/home/vm1/.ivy2/cache/org.scala-lang/scala-compiler/jars/scala-compiler-2.11.8.jar:/home/vm1/.ivy2/cache/org.scala-lang/scala-reflect/jars/scala-reflect-2.11.8.jar:/home/vm1/.ivy2/cache/org.scala-lang.modules/scala-xml_2.11/bundles/scala-xml_2.11-1.0.4.jar:/home/vm1/.ivy2/cache/org.scala-lang.modules/scala-parser-combinators_2.11/bundles/scala-parser-combinators_2.11-1.0.4.jar:/home/vm1/.ivy2/cache/org.glassfish.jersey.core/jersey-client/jars/jersey-client-2.22.2.jar:/home/vm1/.ivy2/cache/javax.ws.rs/javax.ws.rs-api/jars/javax.ws.rs-api-2.0.1.jar:/home/vm1/.ivy2/cache/org.glassfish.jersey.core/jersey-common/jars/jersey-common-2.22.2.jar:/home/vm1/.ivy2/cache/javax.annotation/javax.annotation-api/jars/javax.annotation-api-1.2.jar:/home/vm1/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar:/home/vm1/.ivy2/cache/org.glassfish.hk2/hk2-api/jars/hk2-api-2.4.0-b34.jar:/home/vm1/.ivy2/cache/org.glassfish.hk2/hk2-utils/jars/hk2-utils-2.4.0-b34.jar:/home/vm1/.ivy2/cache/org.glassfish.hk2.external/aopalliance-repackaged/jars/aopalliance-repackaged-2.4.0-b34.jar:/home/vm1/.ivy2/cache/org.glassfish.hk2.external/javax.inject/jars/javax.inject-2.4.0-b34.jar:/home/vm1/.ivy2/cache/org.glassfish.hk2/hk2-locator/jars/hk2-locator-2.4.0-b34.jar:/home/vm1/.ivy2/cache/org.javassist/javassist/bundles/javassist-3.18.1-GA.jar:/home/vm1/.ivy2/cache/org.glassfish.hk2/osgi-resource-locator/jars/osgi-resource-locator-1.0.1.jar:/home/vm1/.ivy2/cache/org.glassfish.jersey.core/jersey-server/jars/jersey-server-2.22.2.jar:/home/vm1/.ivy2/cache/org.glassfish.jersey.media/jersey-media-jaxb/jars/jersey-media-jaxb-2.22.2.jar:/home/vm1/.ivy2/cache/javax.validation/validation-api/jars/validation-api-1.1.0.Final.jar:/home/vm1/.ivy2/cache/org.glassfish.jersey.containers/jersey-container-servlet/jars/jersey-container-servlet-2.22.2.jar:/home/vm1/.ivy2/cache/org.glassfish.jersey.containers/jersey-container-servlet-core/jars/jersey-container-servlet-core-2.22.2.jar:/home/vm1/.ivy2/cache/com.clearspring.analytics/stream/jars/stream-2.7.0.jar:/home/vm1/.ivy2/cache/io.dropwizard.metrics/metrics-jvm/bundles/metrics-jvm-3.1.5.jar:/home/vm1/.ivy2/cache/io.dropwizard.metrics/metrics-json/bundles/metrics-json-3.1.5.jar:/home/vm1/.ivy2/cache/io.dropwizard.metrics/metrics-graphite/bundles/metrics-graphite-3.1.5.jar:/home/vm1/.ivy2/cache/com.fasterxml.jackson.module/jackson-module-scala_2.11/bundles/jackson-module-scala_2.11-2.6.7.1.jar:/home/vm1/.ivy2/cache/com.fasterxml.jackson.module/jackson-module-paranamer/bundles/jackson-module-paranamer-2.7.9.jar:/home/vm1/.ivy2/cache/com.thoughtworks.paranamer/paranamer/bundles/paranamer-2.8.jar:/home/vm1/.ivy2/cache/org.apache.ivy/ivy/jars/ivy-2.4.0.jar:/home/vm1/.ivy2/cache/oro/oro/jars/oro-2.0.8.jar:/home/vm1/.ivy2/cache/net.razorvine/pyrolite/jars/pyrolite-4.13.jar:/home/vm1/.ivy2/cache/net.sf.py4j/py4j/jars/py4j-0.10.7.jar:/home/vm1/.ivy2/cache/org.codehaus.janino/janino/jars/janino-3.0.8.jar:/home/vm1/.ivy2/cache/org.codehaus.janino/commons-compiler/jars/commons-compiler-3.0.8.jar:/home/vm1/.ivy2/cache/org.antlr/antlr4-runtime/jars/antlr4-runtime-4.7.jar:/home/vm1/.ivy2/cache/com.univocity/univocity-parsers/jars/univocity-parsers-2.5.9.jar:/home/vm1/.ivy2/cache/org.apache.orc/orc-core/jars/orc-core-1.4.4-nohive.jar:/home/vm1/.ivy2/cache/io.airlift/aircompressor/jars/aircompressor-0.8.jar:/home/vm1/.ivy2/cache/org.apache.orc/orc-mapreduce/jars/orc-mapreduce-1.4.4-nohive.jar:/home/vm1/.ivy2/cache/org.apache.parquet/parquet-column/jars/parquet-column-1.8.3.jar:/home/vm1/.ivy2/cache/org.apache.parquet/parquet-common/jars/parquet-common-1.8.3.jar:/home/vm1/.ivy2/cache/org.apache.parquet/parquet-encoding/jars/parquet-encoding-1.8.3.jar:/home/vm1/.ivy2/cache/org.apache.parquet/parquet-hadoop/jars/parquet-hadoop-1.8.3.jar:/home/vm1/.ivy2/cache/org.apache.parquet/parquet-format/jars/parquet-format-2.3.1.jar:/home/vm1/.ivy2/cache/org.apache.parquet/parquet-jackson/jars/parquet-jackson-1.8.3.jar:/home/vm1/.ivy2/cache/org.apache.arrow/arrow-vector/jars/arrow-vector-0.8.0.jar:/home/vm1/.ivy2/cache/org.apache.arrow/arrow-format/jars/arrow-format-0.8.0.jar:/home/vm1/.ivy2/cache/com.vlkan/flatbuffers/jars/flatbuffers-1.2.0-3f79e055.jar:/home/vm1/.ivy2/cache/org.apache.arrow/arrow-memory/jars/arrow-memory-0.8.0.jar:/home/vm1/.ivy2/cache/com.google.code.findbugs/jsr305/jars/jsr305-3.0.2.jar:/home/vm1/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.25.jar:/home/vm1/.ivy2/cache/joda-time/joda-time/jars/joda-time-2.9.9.jar:/home/vm1/.ivy2/cache/com.fasterxml.jackson.core/jackson-core/bundles/jackson-core-2.7.9.jar:/home/vm1/.ivy2/cache/com.carrotsearch/hppc/bundles/hppc-0.7.2.jar:/home/vm1/.ivy2/cache/org.apache.kafka/kafka-clients/jars/kafka-clients-0.10.0.1.jar:/home/vm1/.ivy2/cache/net.jpountz.lz4/lz4/jars/lz4-1.3.0.jar[0m
[0m[[0mdebug[0m] [0mScala compilation took 3.189860716 s[0m
[0m[[0mdebug[0m] [0mJava compilation took 1.149592198 s[0m
[0m[[0mdebug[0m] [0mJava analysis took 0.002746966 s[0m
[0m[[0mdebug[0m] [0mJava compile + analysis took 1.156508159 s[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaDataConsumer.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaDataConsumer.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaDataConsumer.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaDataConsumer.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaDataConsumer.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	internalConsumer, notify, unapply, curried, wait, copy$default$2, $asInstanceOf, topicPartition, productArity, equals, asInstanceOf, initializeLogIfNecessary, synchronized, $isInstanceOf, tupled, logTrace, canEqual, isTraceEnabled, initializeLogIfNecessary$default$2, productPrefix, markedForClose, logName, notifyAll, isInstanceOf, kafkaParams, KafkaDataConsumer, <init>, InternalKafkaConsumer, apply, ==, clone, $init$, AvailableOffsetRange, copy, earliest, toString, logError, !=, get, release, getClass, latest, logWarning, copy$default$1, close, ne, getAvailableOffsetRange, eq, productIterator, log, acquire, inUse, ##, finalize, productElement, hashCode, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceRDD.scala: Set(topicPartition, asInstanceOf, isInstanceOf, KafkaDataConsumer, <init>, apply, ==, AvailableOffsetRange, earliest, toString, logError, get, release, latest, ne, getAvailableOffsetRange, eq, acquire, logInfo)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaContinuousReader.scala: Set(topicPartition, asInstanceOf, synchronized, isInstanceOf, kafkaParams, KafkaDataConsumer, <init>, apply, ==, AvailableOffsetRange, earliest, toString, !=, get, release, latest, logWarning, close, ne, getAvailableOffsetRange, eq, acquire, logInfo)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSink.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSink.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSink.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSink.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSink.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, wait, $asInstanceOf, equals, asInstanceOf, initializeLogIfNecessary, synchronized, $isInstanceOf, logTrace, isTraceEnabled, initializeLogIfNecessary$default$2, logName, notifyAll, isInstanceOf, <init>, ==, clone, KafkaSink, $init$, toString, logError, !=, getClass, logWarning, ne, addBatch, eq, log, ##, finalize, hashCode, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, KafkaSink, toString, !=, logWarning, ne, eq, hashCode, logDebug)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriter.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriter.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriter.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriter.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriter.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, validateQuery$default$3, wait, $asInstanceOf, equals, asInstanceOf, initializeLogIfNecessary, synchronized, VALUE_ATTRIBUTE_NAME, $isInstanceOf, KafkaWriter, logTrace, isTraceEnabled, initializeLogIfNecessary$default$2, KEY_ATTRIBUTE_NAME, write$default$4, logName, notifyAll, isInstanceOf, TOPIC_ATTRIBUTE_NAME, ==, clone, validateQuery, $init$, toString, logError, !=, getClass, logWarning, ne, eq, write, log, ##, finalize, hashCode, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriteTask.scala: Set(VALUE_ATTRIBUTE_NAME, KafkaWriter, KEY_ATTRIBUTE_NAME, TOPIC_ATTRIBUTE_NAME, ==, toString, !=)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSink.scala: Set(KafkaWriter, write, logInfo)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala: Set(asInstanceOf, KafkaWriter, isInstanceOf, ==, validateQuery, toString, !=, logWarning, ne, eq, write, hashCode, logDebug)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaStreamWriter.scala: Set(asInstanceOf, KafkaWriter, isInstanceOf, ==, validateQuery, toString, !=, eq)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaContinuousReader.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaContinuousReader.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaContinuousReader.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaContinuousReader.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaContinuousReader.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, readSchema, createDataReader, needsReconfiguration, wait, setStartOffset, copy$default$2, $asInstanceOf, topicPartition, commit, copy$default$5, mergeOffsets, productArity, equals, createDataReaderFactories, asInstanceOf, initializeLogIfNecessary, synchronized, KafkaContinuousDataReader, createUnsafeRowReaderFactories, $isInstanceOf, logTrace, canEqual, copy$default$4, isTraceEnabled, initializeLogIfNecessary$default$2, productPrefix, stop, logName, notifyAll, KafkaContinuousReader, isInstanceOf, kafkaParams, failOnDataLoss, <init>, ==, getStartOffset, clone, $init$, next, copy$default$3, copy, startOffset, pollTimeoutMs, toString, preferredLocations, deserializeOffset, getOffset, logError, !=, get, getClass, logWarning, copy$default$1, close, ne, knownPartitions, eq, KafkaContinuousDataReaderFactory, productIterator, log, ##, finalize, productElement, hashCode, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala: Set(asInstanceOf, KafkaContinuousReader, isInstanceOf, kafkaParams, failOnDataLoss, <init>, ==, toString, !=, get, logWarning, ne, eq, hashCode, logDebug)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceRDD.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceRDD.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceRDD.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceRDD.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceRDD.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	creationSite, zipPartitions, markCheckpointed, notify, mapPartitionsWithIndex$default$2, unpersist, sortBy$default$2, parent, isLocallyCheckpointed, getOrCompute, distinct$default$2, partitioner, coalesce, name, count, wait, copy$default$2, $asInstanceOf, isCheckpointedAndMaterialized, mapPartitions, setName, KafkaSourceRDDOffsetRange, topicPartition, size, union, coalesce$default$3, zip, localCheckpoint, map, productArity, subtract, equals, pipe$default$5, intersection, sortBy$default$3, foreachPartition, countApprox$default$2, scope, asInstanceOf, context, initializeLogIfNecessary, subtract$default$3, getPreferredLocations, glom, offsetRange, sortBy, pipe$default$6, KafkaSourceRDDPartition, doCheckpoint, synchronized, pipe$default$2, repartition$default$2, partition, aggregate, $isInstanceOf, compute, mapPartitions$default$2, min, getCheckpointFile, untilOffset, fold, getOutputDeterministicLevel, logTrace, canEqual, treeAggregate$default$4, copy$default$4, isTraceEnabled, initializeLogIfNecessary$default$2, zipWithUniqueId, productPrefix, iterator, coalesce$default$4, fromOffset, countApprox, logName, notifyAll, countApproxDistinct$default$1, conf, getNarrowAncestors, preferredLoc, cache, getNumPartitions, isInstanceOf, filter, pipe$default$3, countByValueApprox$default$3, unpersist$default$1, persist, checkpointData, <init>, isCheckpointed, id, mapPartitionsWithIndexInternal, countApproxDistinct, max, outputDeterministicLevel, randomSampleWithRange, toDebugString, ++, flatMap, take, countByValue$default$1, KafkaSourceRDD, groupBy, treeReduce$default$2, ==, randomSplit$default$2, groupBy$default$4, clone, distinct, retag, foreach, treeReduce, toLocalIterator, sparkContext, reduce, saveAsTextFile, $init$, takeSample$default$3, zipWithIndex, getStorageLevel, checkpoint, first, countByValue, countByValueApprox$default$2, elementClassTag, copy$default$3, sample, copy, pipe$default$7, toString, mapPartitionsInternal, preferredLocations, logError, !=, topic, partitions, collect, getClass, pipe, logWarning, getPartitions, copy$default$1, pipe$default$4, cartesian, repartition, mapPartitionsWithIndexInternal$default$2, collectPartitions, mapPartitionsInternal$default$2, clearDependencies, isEmpty, sample$default$3, ne, countByValueApprox, getDependencies, mapPartitionsWithIndex, intersection$default$3, keyBy, randomSplit, top, coalesce$default$2, getCreationSite, computeOrReadCheckpoint, dependencies, saveAsObjectFile, mapPartitionsWithIndexInternal$default$3, toJavaRDD, eq, isReliablyCheckpointed, productIterator, withScope, log, ##, finalize, treeAggregate, index, productElement, hashCode, takeOrdered, logDebug, firstParent, logInfo, takeSample.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSource.scala: Set(KafkaSourceRDDOffsetRange, topicPartition, size, map, asInstanceOf, sortBy, synchronized, partition, min, untilOffset, fromOffset, conf, preferredLoc, isInstanceOf, filter, <init>, id, flatMap, KafkaSourceRDD, ==, foreach, sparkContext, toString, !=, topic, logWarning, isEmpty, ne, hashCode, logDebug, logInfo)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaRelation.scala: Set(KafkaSourceRDDOffsetRange, topicPartition, map, asInstanceOf, sortBy, partition, untilOffset, fromOffset, conf, isInstanceOf, <init>, id, KafkaSourceRDD, ==, sparkContext, toString, !=, topic, partitions, ne, logDebug, logInfo)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetReader.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetReader.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetReader.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetReader.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetReader.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, wait, $asInstanceOf, equals, asInstanceOf, initializeLogIfNecessary, fetchTopicPartitions, synchronized, $isInstanceOf, logTrace, isTraceEnabled, initializeLogIfNecessary$default$2, logName, notifyAll, isInstanceOf, consumer, <init>, ==, execContext, clone, $init$, kafkaSchema, toString, logError, !=, KafkaOffsetReader, fetchLatestOffsets, getClass, logWarning, fetchEarliestOffsets, close, ne, kafkaReaderThread, eq, log, ##, finalize, hashCode, logDebug, fetchSpecificOffsets, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSource.scala: Set(asInstanceOf, synchronized, isInstanceOf, <init>, ==, kafkaSchema, toString, !=, KafkaOffsetReader, fetchLatestOffsets, logWarning, fetchEarliestOffsets, close, ne, hashCode, logDebug, fetchSpecificOffsets, logInfo)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaRelation.scala: Set(asInstanceOf, fetchTopicPartitions, isInstanceOf, <init>, ==, kafkaSchema, toString, !=, KafkaOffsetReader, close, ne, logDebug, logInfo)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaContinuousReader.scala: Set(asInstanceOf, synchronized, isInstanceOf, consumer, <init>, ==, kafkaSchema, toString, !=, KafkaOffsetReader, fetchLatestOffsets, logWarning, fetchEarliestOffsets, close, ne, eq, fetchSpecificOffsets, logInfo)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala: Set(asInstanceOf, isInstanceOf, consumer, <init>, ==, kafkaSchema, toString, !=, KafkaOffsetReader, logWarning, ne, eq, hashCode, logDebug)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceOffset.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceOffset.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceOffset.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceOffset.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceOffset.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, unapply, wait, copy$default$2, $asInstanceOf, topicPartition, productArity, equals, json, asInstanceOf, synchronized, $isInstanceOf, canEqual, partitionOffset, productPrefix, notifyAll, isInstanceOf, getPartitionOffsets, <init>, apply, ==, clone, KafkaSourcePartitionOffset, $init$, copy, toString, !=, getClass, copy$default$1, KafkaSourceOffset, ne, eq, productIterator, ##, finalize, partitionToOffsets, productElement, hashCode.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSource.scala: Set(topicPartition, json, asInstanceOf, synchronized, isInstanceOf, getPartitionOffsets, <init>, apply, ==, toString, !=, KafkaSourceOffset, ne, partitionToOffsets, hashCode)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaContinuousReader.scala: Set(topicPartition, json, asInstanceOf, synchronized, partitionOffset, isInstanceOf, getPartitionOffsets, <init>, apply, ==, KafkaSourcePartitionOffset, toString, !=, KafkaSourceOffset, ne, eq)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetReader.scala: Set(unapply, asInstanceOf, synchronized, isInstanceOf, <init>, apply, ==, toString, !=, KafkaSourceOffset, ne)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/ConsumerStrategy.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/ConsumerStrategy.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/ConsumerStrategy.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/ConsumerStrategy.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/ConsumerStrategy.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, topics, wait, $asInstanceOf, productArity, equals, topicPattern, asInstanceOf, synchronized, $isInstanceOf, SubscribeStrategy, canEqual, productPrefix, notifyAll, ConsumerStrategy, isInstanceOf, createConsumer, SubscribePatternStrategy, <init>, ==, clone, $init$, copy, toString, !=, partitions, getClass, copy$default$1, ne, eq, productIterator, AssignStrategy, ##, finalize, productElement, hashCode.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaRelation.scala: Set(asInstanceOf, ConsumerStrategy, isInstanceOf, <init>, ==, toString, !=, partitions, ne)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetReader.scala: Set(asInstanceOf, synchronized, ConsumerStrategy, isInstanceOf, createConsumer, <init>, ==, toString, !=, partitions, ne)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala: Set(topics, asInstanceOf, SubscribeStrategy, ConsumerStrategy, isInstanceOf, SubscribePatternStrategy, <init>, ==, toString, !=, partitions, ne, eq, AssignStrategy, hashCode)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, kafkaParamsForProducer, wait, $asInstanceOf, TOPIC_OPTION_KEY, sourceSchema, equals, kafkaParamsForDriver, asInstanceOf, initializeLogIfNecessary, synchronized, getKafkaOffsetRangeLimit, kafkaParamsForExecutors, $isInstanceOf, logTrace, STARTING_OFFSETS_OPTION_KEY, isTraceEnabled, initializeLogIfNecessary$default$2, logName, notifyAll, isInstanceOf, <init>, ENDING_OFFSETS_OPTION_KEY, createSink, ==, clone, $init$, KafkaSourceProvider, createContinuousReader, toString, createRelation, logError, !=, getClass, logWarning, shortName, ne, createSource, createStreamWriter, eq, log, ##, finalize, hashCode, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriteTask.scala: Set(TOPIC_OPTION_KEY, <init>, ==, KafkaSourceProvider, toString, !=)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaRelation.scala: Set(kafkaParamsForDriver, asInstanceOf, kafkaParamsForExecutors, isInstanceOf, <init>, ==, KafkaSourceProvider, toString, !=, ne, logDebug, logInfo)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriter.scala: Set(TOPIC_OPTION_KEY, <init>, ==, KafkaSourceProvider)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/package-info.java...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/package-info.java...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/package-info.java)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/package-info.java)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/package-info.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/JsonUtils.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/JsonUtils.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/JsonUtils.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/JsonUtils.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/JsonUtils.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] None of the modified names appears in /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceOffset.scala. This dependency is not being considered for invalidation.[0m
[0m[[0mdebug[0m] [0m[naha] None of the modified names appears in /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaContinuousReader.scala. This dependency is not being considered for invalidation.[0m
[0m[[0mdebug[0m] [0m[naha] None of the modified names appears in /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala. This dependency is not being considered for invalidation.[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/CachedKafkaProducer.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/CachedKafkaProducer.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/CachedKafkaProducer.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/CachedKafkaProducer.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/CachedKafkaProducer.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, wait, $asInstanceOf, equals, asInstanceOf, initializeLogIfNecessary, synchronized, $isInstanceOf, logTrace, isTraceEnabled, initializeLogIfNecessary$default$2, logName, notifyAll, isInstanceOf, ==, getOrCreate, clone, $init$, toString, logError, !=, getClass, logWarning, close, CachedKafkaProducer, ne, eq, log, ##, finalize, hashCode, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriteTask.scala: Set(==, getOrCreate, toString, !=, CachedKafkaProducer)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaStreamWriter.scala: Set(asInstanceOf, isInstanceOf, ==, getOrCreate, toString, !=, close, CachedKafkaProducer, eq)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetRangeLimit.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetRangeLimit.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetRangeLimit.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetRangeLimit.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetRangeLimit.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, SpecificOffsetRangeLimit, wait, $asInstanceOf, LATEST, EarliestOffsetRangeLimit, productArity, equals, asInstanceOf, synchronized, $isInstanceOf, partitionOffsets, canEqual, productPrefix, notifyAll, isInstanceOf, <init>, LatestOffsetRangeLimit, ==, clone, $init$, KafkaOffsetRangeLimit, copy, toString, !=, getClass, copy$default$1, ne, eq, productIterator, ##, finalize, productElement, hashCode, EARLIEST.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaContinuousReader.scala: Set(SpecificOffsetRangeLimit, EarliestOffsetRangeLimit, asInstanceOf, synchronized, partitionOffsets, isInstanceOf, <init>, LatestOffsetRangeLimit, ==, KafkaOffsetRangeLimit, toString, !=, ne, eq)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaRelation.scala: Set(SpecificOffsetRangeLimit, LATEST, EarliestOffsetRangeLimit, asInstanceOf, partitionOffsets, isInstanceOf, <init>, LatestOffsetRangeLimit, ==, KafkaOffsetRangeLimit, toString, !=, ne, EARLIEST)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala: Set(SpecificOffsetRangeLimit, LATEST, EarliestOffsetRangeLimit, asInstanceOf, partitionOffsets, isInstanceOf, <init>, LatestOffsetRangeLimit, ==, KafkaOffsetRangeLimit, toString, !=, ne, eq, hashCode, EARLIEST)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaOffsetReader.scala: Set(LATEST, asInstanceOf, synchronized, partitionOffsets, isInstanceOf, <init>, ==, KafkaOffsetRangeLimit, toString, !=, ne, EARLIEST)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSource.scala: Set(SpecificOffsetRangeLimit, EarliestOffsetRangeLimit, asInstanceOf, synchronized, partitionOffsets, isInstanceOf, <init>, LatestOffsetRangeLimit, ==, KafkaOffsetRangeLimit, toString, !=, ne, hashCode)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceRDD.scala: Set(LATEST, asInstanceOf, isInstanceOf, <init>, ==, KafkaOffsetRangeLimit, toString, ne, eq, EARLIEST)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriteTask.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriteTask.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriteTask.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Including /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaStreamWriter.scala by /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriteTask.scala[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaStreamWriter.scala, /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriteTask.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriteTask.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, execute, wait, $asInstanceOf, projection, KafkaRowWriter, equals, failedWrite, asInstanceOf, synchronized, $isInstanceOf, checkForErrors, KafkaWriteTask, notifyAll, isInstanceOf, <init>, ==, sendRow, clone, toString, !=, getClass, close, ne, eq, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, toString, !=, ne, eq, hashCode)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaWriter.scala: Set(execute, KafkaWriteTask, <init>, ==, close)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaStreamWriter.scala: Set(KafkaRowWriter, asInstanceOf, checkForErrors, isInstanceOf, <init>, ==, sendRow, toString, !=, close, eq)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaRelation.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaRelation.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaRelation.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaRelation.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaRelation.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, wait, $asInstanceOf, equals, buildScan, asInstanceOf, initializeLogIfNecessary, unhandledFilters, synchronized, $isInstanceOf, logTrace, isTraceEnabled, initializeLogIfNecessary$default$2, logName, notifyAll, isInstanceOf, <init>, schema, ==, sqlContext, clone, KafkaRelation, sizeInBytes, $init$, toString, logError, !=, getClass, logWarning, ne, eq, log, ##, finalize, hashCode, logDebug, logInfo, needConversion.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala: Set(asInstanceOf, isInstanceOf, <init>, schema, ==, sqlContext, KafkaRelation, toString, !=, logWarning, ne, eq, hashCode, logDebug)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaStreamWriter.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaStreamWriter.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaStreamWriter.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaStreamWriter.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaStreamWriter.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, KafkaStreamWriterFactory, wait, copy$default$2, $asInstanceOf, commit, createDataWriter, projection, productArity, equals, failedWrite, KafkaStreamWriter, producerParams, asInstanceOf, synchronized, createInternalRowWriterFactory, $isInstanceOf, checkForErrors, createWriterFactory, canEqual, productPrefix, notifyAll, isInstanceOf, <init>, schema, ==, sendRow, clone, $init$, KafkaWriterCommitMessage, copy$default$3, copy, toString, !=, topic, getClass, copy$default$1, close, ne, KafkaStreamDataWriter, eq, productIterator, write, ##, finalize, productElement, hashCode, abort.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala: Set(KafkaStreamWriter, producerParams, asInstanceOf, isInstanceOf, <init>, schema, ==, toString, !=, topic, ne, eq, write, hashCode)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSource.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Invalidating (transitively) by inheritance from /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSource.scala...[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSource.scala)[0m
[0m[[0mdebug[0m] [0m[naha] Invalidated by transitive inheritance dependency: Set(/usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSource.scala)[0m
[0m[[0mdebug[0m] [0m[naha] The /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSource.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m[naha] 	notify, KafkaSource, wait, $asInstanceOf, commit, getBatch, equals, getSortedExecutorList, asInstanceOf, initializeLogIfNecessary, synchronized, $isInstanceOf, logTrace, isTraceEnabled, initializeLogIfNecessary$default$2, stop, logName, notifyAll, isInstanceOf, VERSION, <init>, schema, ==, clone, $init$, toString, INSTRUCTION_FOR_FAIL_ON_DATA_LOSS_FALSE, getOffset, logError, !=, getClass, logWarning, ne, INSTRUCTION_FOR_FAIL_ON_DATA_LOSS_TRUE, eq, log, ##, finalize, hashCode, logDebug, logInfo.[0m
[0m[[0mdebug[0m] [0m[naha] All member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaDataConsumer.scala: Set(KafkaSource, asInstanceOf, synchronized, isInstanceOf, <init>, ==, toString, INSTRUCTION_FOR_FAIL_ON_DATA_LOSS_FALSE, logError, !=, logWarning, INSTRUCTION_FOR_FAIL_ON_DATA_LOSS_TRUE, eq, logDebug, logInfo)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaContinuousReader.scala: Set(KafkaSource, asInstanceOf, synchronized, isInstanceOf, <init>, ==, toString, INSTRUCTION_FOR_FAIL_ON_DATA_LOSS_FALSE, !=, logWarning, ne, INSTRUCTION_FOR_FAIL_ON_DATA_LOSS_TRUE, eq, logInfo)[0m
[0m[[0mdebug[0m] [0m[naha] The following modified names cause invalidation of /usr/local/spark-2.3.2-bin-hadoop2.7/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala: Set(KafkaSource, asInstanceOf, isInstanceOf, <init>, schema, ==, toString, !=, logWarning, ne, eq, hashCode, logDebug)[0m
[0m[[0mdebug[0m] [0m[naha] New invalidations:[0m
[0m[[0mdebug[0m] [0m[naha] 	Set()[0m
[0m[[0mdebug[0m] [0m[naha] Initial set of included nodes: Set()[0m
[0m[[0mdebug[0m] [0m[naha] Previously invalidated, but (transitively) depend on new invalidations:[0m
[0m[[0mdebug[0m] [0m[naha] 	Set()[0m
[0m[[0mdebug[0m] [0m[naha] All newly invalidated sources after taking into account (previously) recompiled sources:Set()[0m
